Pack	Topic	Problem Name	Problem Link	Question Statement	Time Complexity	Memory Complexity	Expectation	A	B	C	D	Correct	Message Response For A	Message Response For B	Message Response For C	Message Response For D	Hint	C++ Code Link	Python Code Link	Java Code Link	English Video Solution
Coding Interviews	Arrays: Prefix Sum	Maximum Difference Between Increasing Elements	https://leetcode.com/problems/maximum-difference-between-increasing-elements/	Given a **0-indexed** integer array *nums* of size *n*, find the maximum difference between *nums[i]* and *nums[j]* (i.e., *nums[j]* - *nums[i]*), such that *0 <= i < j < n* and *nums[i]* < *nums[j]*.  <br><br>Return the maximum difference. If no such *i* and *j* exists, return *-1*.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Cumulative Sum	Sliding Window	Sliding Window + Hash Table	Linear Scan + Single Pointer	D	**Incorrect!**  <br><br>This is slightly more complex than the correct answer.  While the time complexity is the same as *Linear Scan + Single Pointer*, a prefix sum approach involves creating additional arrays, leading to poorer space complexity.	Not quite the optimal approach!  <br><br>A sliding window is typically used when we're looking for a contiguous array of a fixed length.	Extremely inefficient.<br><br>This would be *O(n)* in memory with no improvement in time complexity, whereas the optimal solution is *O(1)* in memory.	**Correct!**<br><br>We can iterate through the array from back to front in a single pass, keeping track of the MAXIMUM element found so far, while checking each new element to see if it's less than the maximum element.<br><br>If so, we calculate the difference between this element and the maximum, and then update the maximum difference if necessary.<br><br>Time Complexity: O(n)<br>Memory Complexity: O(1)	Using nested loops, consider all possible pairs (i, j) where i < j and nums[i] < nums[j].<br>For each pair, compute their difference and keep track of the maximum difference found so far.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Maximum%20Difference%20Between%20Increasing%20Elements.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Maximum%20Difference%20Between%20Increasing%20Elements.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Maximum%20Difference%20Between%20Increasing%20Elements.java	https://youtu.be/ULmsRWTwFpQ
Coding Interviews	Arrays:Sliding Window	SubArray Sum Equals K	https://leetcode.com/problems/subarray-sum-equals-k/	Given an array of integers *nums* and an integer *k*, return the total number of subarrays whose sum equals to *k*.<br><br>A subarray is a contiguous non-empty sequence of elements within an array.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Cumulative Sum	Binary Indexed Tree (BIT)	Sliding Window + Hash Table	Sorting + Sliding Window	C	Feasible, but *inefficient* as it typically involves nested loops.<br><br>We'd precompute the prefix sums of the given array, with the *ith* prefix sum representing the sum of elements from index 0 to index *i* in the array.<br><br>The subarray sum between two indices *i* and *j* can then be computed as the difference between the prefix sums at these indices.<br><br>Time Complexity: **O(n^2)**, due to the nexted loop.	While an obscure and slightly inefficient approach, the BIT can conceivably compute the sum of a range of elements.<br><br>The subarray whose sum equals the target value *k* can be found by iteratively adding elements to the BIT and checking if the difference between the current sum and k has been seen before.<br><br>The time complexity of this approach is O(n log(n)), with poor space complexity too.	**Correct!**<br><br>This only needs a *single pass* over the array, and uses *constant space* to maintain the hash table!<br><br>The hash table also allows for constant time lookups of the sum of elements up to each index, which helps to reduce the time complexity of the algorithm.<br><br>Time Complexity: O(n)<br>Memory Complexity: O(n)	**Suboptimal.**<br><br>This approach involves sorting the given array and then iterating over it to compute the sum of all possible subarrays. The idea is that the sorted array will have all the subarrays with the same sum grouped together, which can then be counted using a sliding window approach.<br><br>However, the sorting step takes O(n log(n)) time.	Consider all possible subarrays of the given array and calculate their sum, with time complexity of **O(n^3)**.  We can then count the number of subarrays whose sum equals to k.<br><br>This can be done using two nested loops to iterate through all possible starting and ending indices of the subarrays and calculating their sum.<br><br>If the sum equals k, increment a counter.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Subarray%20Sum%20Equals%20K.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Subarray%20Sum%20Equals%20K.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Subarray%20Sum%20Equals%20K.java	https://youtu.be/Aj4na0jQAwY
Coding Interviews	Arrays: Prefix Sum	Contiguous Array	https://leetcode.com/problems/contiguous-array/	Given a binary array *nums*, return the **maximum length of a contiguous subarray** with an equal number of *0* and *1*.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Sliding Window + Hash Table	Stack	Kadane's Algorithm	Two Linear Passes	A	**Correct!**<br><br>The given solutions make use of a relatively famous application of the sliding window technique to solve this problem! I strongly encourage you to try it yourself!<br><br>Time Complexity: O(n)<br>Memory Complexity: O(n)	Not quite the best approach!<br><br>It **IS O(n) in both time and memory complexity**, but requires more operations to maintain the stack and find the farthest elements, which makes it slightly **inferior** to the **sliding window** approach.	This would **not** be a good approach for solving this kind of problem!	In this **suboptimal** attempt, the first pass replaces all 0s with -1 and computes the prefix sums of the resulting array. In the second pass, the maximum length of the contiguous subarray with zero sum is computed.<br><br>Time Complexity: **O(n)**<br>Space Complexity: **O(n)** due to the use of prefix sums, but it requires two passes over the input array, making it less efficient than the optimal sliding window approach. We prefer both the sliding window and the stack to this method.	Consider all possible subarrays and for each subarray count the number of 0's and 1's. If the number of 0's and 1's is the same, update the maximum length of subarrays found so far.<br><br>Time Complexity: O(n^3) as we need to consider all possible subarrays, and for each subarray, we would need to count the number of 0's and 1's, which would take O(n) time.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Contiguous%20Array.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Contiguous%20Array.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Contiguous%20Array.java	https://youtu.be/OY_qStggenA
Coding Interviews	Arrays: Sliding Window	Contains Duplicate II	https://leetcode.com/problems/contains-duplicate-ii/	Given an integer array *nums* and an integer *k*, return *true* if there are two **distinct indices** *i* and *j* in the array such that *nums[i] == nums[j]* and *abs(i - j) <= k*.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Cumulative Sum + Hash Table	Sorting	Sliding Window + Hash Table	Sliding Window + Cleverly Nested Loops	C	This idea just doesn't work at all.<br><br>We're looking for a matching pair in the array, rather than anything that involves computing a sum.	**Overly complicated!**<br><br>At best, this would yield a solution of O(n log(n)) time due to the sorting step.	**Correct!**<br><br>In this approach, we maintain a window of size *k* and slide it over the input array. We use a hash table to efficiently keep track of the count of each element within the current window.  The two pointers keep track of the current window, and we keep tack of the maximum count seen so far<br><br>Whenever we slide the window to the right, we decrement the count of the element that is no longer in the window and increment the count of the new element that enters the window. We also keep track of the maximum count seen so far within any window of size k. If this maximum count is greater than or equal to t, we return true.<br><br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	However ingenious, nested loops will remain **O(n^2)** with this approach!<br><br>This would involve using a sliding window of size k to check every possible pair of elements within the window, moving the window one element at a time until we have checked all possible pairs.	We'd simply check every pair of indices *(i, j)* such that *i < j* and *nums[i] == nums[j]* and *abs(i - j) <= k*. Use nested loops to iterate over all possible pairs of indices, and then checking the conditions for each pair. If a pair is found that satisfies the conditions, return true. Otherwise, return false.<br><br>The time complexity of this approach would be O(n^2).<br>The space complexity would be O(1), since we are only using a constant amount of extra space to store the loop variables and the boolean flag for the result.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Contains%20Duplicate%20II.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Contains%20Duplicate%20II.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Contains%20Duplicate%20II.java	https://youtu.be/tJLbrZdUuXk
Coding Interviews	Arrays: Sliding Window	Max Consecutive Ones III	https://leetcode.com/problems/max-consecutive-ones-iii/	Given a binary array *nums* and an integer *k*, return the **maximum number of consecutive** *1*'s in the array if you can flip **at most** *k* *0*'s.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Two Pointers	Sliding Window	Floyd's Tortoise And Hare	Hash Table	B	**Incorrect!**<br><br>This approach is similar to the correct one, but it does not consider the fact that we can flip at most k zeroes. It may update the result even when it has already flipped k zeros, leading to an incorrect answer.	**Correct!**<br><br>To solve this, we maintain a window of the required elements and slide it over the array. In our solution, we keep a window of consecutive 1's while tracking the number of 0's encountered inside the window.<br><br>If the number of 0's exceeds k, we move the window's start index to the right until the number of 0's inside the window is less than or equal to k.<br><br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	**No!**	**Suboptimal**<br><br>This uses a hash table to store the number of zeroes and ones in each subarray of the input array, then iterates through it to find the subarray with the maximum number of ones that can be obtained by flipping at most k zeroes.<br><br>This approach is inefficient in terms of both time and space!	1)Initialize a variable maxLen to 0.<br>2) Iterate over all possible subarrays of the given array using two nested loops, one for the start index and one for the end index.<br>3) Count the number of zeros in the current subarray. If the count is less than or equal to k, update maxLen to the maximum of its current value and the length of the subarray.<br>4) Return maxLen.<br><br>The time complexity is O(n^3), where n is the length of the input array, since it involves iterating over all possible subarrays. Find a more efficient method!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Max%20Consecutive%20Ones%20III.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Max%20Consecutive%20Ones%20III.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Max%20Consecutive%20Ones%20III.java	https://youtu.be/nT2RQWFxmhk
Coding Interviews	Arrays: Sliding Window	Longest Substring Without Repeating Characters	https://leetcode.com/problems/longest-substring-without-repeating-characters/	Given a string *s*, find the length of the **longest substring** without repeating characters.	O(n)	O(min(n,m))	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(min(n,m))**	Stack + Hash Table	Sliding Window + Hash Set	Two Pointers	Sliding Window + Hash Table	D	**Over-engineered!**<br><br>The idea here is to iterate through each character in s, and for each character, we first check if it has been visited before. If it has, we pop characters from the stack until we reach the first occurrence of the current character, and mark all popped characters as unvisited in the hash table.<br><br>We then push the current character onto the stack, mark it as visited, and update the result with the maximum length seen so far.<br><br>This solution has a time complexity of **O(n^2)** in the worst case, while the space complexity is **O(n)**.	**Inefficient!**<br><br>This would combine a sliding window approach with a hash set by maintaining a hash set of characters in the current window and sliding the window along the string. We'd add characters to the hash set while moving the window forward, and remove characters from the hash set while moving it backwards.<br><br>However, the time complexity of this approach would be O(n^2) in the worst case, where n is the length of the input string.	**Not Quite!**<br><br>This is a solid approach, using two pointers to maintain a sliding window of distinct characters. The left pointer can mark the start of the window, with a right pointer expanding the window each time. When encountering a repeating character, we move the left pointer to the index after the repeated character.<br><br>However, the time complexity would be O(2n) in the worst case, where all characters are the same.	**Correct!**<br><br>Our algorithm initializes two pointers, start and end, to the beginning of the string. It then moves the end pointer to the right until it reaches a repeated character. At this point, it moves the start pointer to the next index AFTER the previous occurrence of the repeated character, effectively removing that character and any previous characters from the substring.<br><br>After each iteration, it calculates the length of the current substring and updates the maximum length. Finally, it returns the maximum length.<br><br>Time Complexity: **O(n)**, since it performs a constant number of operations for each character in the string.<br>Space Complexity: **O(min(n, m))**, where m is the size of the character set.	We can use two nested loops to iterate over the starting and ending indices of the substring, with a hash set keeping track of the unique characters in the current substring.<br><br>This would be O(n^3) since we are iterating over all possible substrings, making it extremely inefficient for larger inputs.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Longest%20Substring%20Without%20Repeating%20Characters.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Longest%20Substring%20Without%20Repeating%20Characters.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Longest%20Substring%20Without%20Repeating%20Characters.java	https://youtu.be/6RELwHH8Bl8
Coding Interviews	Arrays: Sliding Window	Maximum Subarray	https://leetcode.com/problems/maximum-subarray/	Given an integer array *nums*, find the **subarray** with the largest sum, and return its *sum*.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Greedy Algorithm	Kadane's Algorithm	Divide And Conquer	Sort + Sum	B	**Rather unwieldy!**<br><br>The idea would be to add the current element at each index to the sum if it increases the sum - and start a new subarray otherwise. This approach may fail for certain input cases, such as when starting a new subarray prematurely would cause the maximum subarray sum to be missed.<br><br>Kadane's algorithm is better for handling all input cases correctly.	**Correct!**<br><br>Kadane's Algorithm works by iterating through the array, calculating the max sum ending at the current index. If the max sum ending at the current index is greater than the current element, then it updates the max sum ending at the current index.<br><br>Finally, it updates the result with the max of the current result and the max sum ending at the current index.<br><br>The time complexity of Kadane's algorithm is **O(n)**, as it only needs to iterate through the array once.<br>Memory Complexity: **O(1)**, as it only uses constant extra space to store the maximum sum ending at the current index and the maximum subarray sum found so far.	**Inefficient** compared to other methods.<br><br>This would divide the array in half, while recursively finding both the maximum subarray sum for each half AND the maximum subarray sum crossing the middle. <br><br>Theese results can then be combined successfully, albeit with a time complexity of O(n log(n)), which is not as efficient as Kadane's Algorithm.<br>It also requires more memory to store the recursive calls and results.	**Incorrect**, as there's no guarantee the subarray must be contiguous. <br><br>Sorting the array can change the order of the elements and therefore break the contiguity of the subarray.	Try all possible subarrays and keep track of the maximum sum.<br><br>This simple approach has a time complexity of O(n^2), which is not efficient for large input sizes.  There is a better way to do this!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Maximum%20Subarray.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Maximum%20Subarray.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Maximum%20Subarray.java	https://youtu.be/MARF46gaCkE
Coding Interviews	Arrays: Sliding Window	Maximum Absolute Sum Of Any Subarray	https://leetcode.com/problems/maximum-absolute-sum-of-any-subarray/	You are given an integer array *nums*. The **absolute sum** of a subarray *[nums(l), nums(l+1), ..., nums(r-1), nums(r)]* is *abs(nums(l) + nums(l+1) + ... + nums(r-1) + nums(r)).<br><br>Return the **maximum** *absolute sum* of **any (possibly empty) subarray** of *nums*.<br><br>Note that abs(x) is defined as follows:<br>If *x* is a negative integer, then *abs(x) = -x.*<br>If *x* is a non-negative integer, then *abs(x) = x*.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Divide And Conquer	Sort and Sum	Kadane's Algorithm	Dynamic Programming	C	**Incorrect.**<br><br>The idea is to divide the array into two subarrays: one with all negative numbers and one with all non-negative numbers. We'd then return the absolute sum of the subarray with the largest sum.<br><br>However, it may not handle cases where the array contains both positive and negative numbers correctly.	**Suboptimal at best!**<br><br>The idea is to sort the array in non-decreasing order and return the absolute sum of the subarray containing the largest and smallest elements.<br><br>However, sorting the array takes **O(n log(n))** time, which is not optimal for this problem. In addition, this approach doesn't consider all subarrays, and it may miss the maximum absolute sum.	**Correct!**<br><br>Our solution applies Kadane's algorithm to find the maximum sum subarray and the minimum sum subarray of the given array. It then takes the maximum of the absolute value of the maximum sum subarray and the absolute value of the minimum sum subarray to get the maximum absolute sum of any subarray.<br><br>Time Complexity: O(n), as it uses Kadane's algorithm twice, with both iterations taking linear time.<br>Space Complexity: O(1), as it only uses constant extra space to store the maximum sum and minimum sum subarrays found so far.	**Madness!**<br><br>The method uses DP to keep track of the maximum and minimum absolute sum of any subarray that ends at each index.<br><br>This approach has a time complexity of O(n^2), due to the use of nested loops that iterate over all previous indices. It can also produce incorrect results, as the maximum absolute sum subarray may not end at the last index. For example, if the array has a single negative number, the maximum absolute sum subarray will be of length 1 and will not end at the last index.	We can iterate through all subarrays of nums and calculate their absolute sums. After that, we return the maximum of all the absolute sums found.<br><br>However, this approach is O(n^3) in time complexity.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Maximum%20Absolute%20Sum%20of%20Any%20Subarray.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Maximum%20Absolute%20Sum%20of%20Any%20Subarray.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Maximum%20Absolute%20Sum%20of%20Any%20Subarray.java	https://youtu.be/fWZQmbkmdAc
Coding Interviews	Arrays: Sliding Window	Maximum Sum Circular Subarray	https://leetcode.com/problems/maximum-sum-circular-subarray/	Given a circular integer array *nums* of length *n*, return the **maximum possible sum** of a **non-empty subarray** of *nums*.<br><br>A **circular array** means the end of the array connects to the beginning of the array. Formally, the next element of *nums[i]* is *nums[(i + 1) % n]* and the previous element of *nums[i]* is *nums[(i - 1 + n) % n]*.<br><br>A **subarray** may only include each element of the fixed buffer *nums* at most once. Formally, for a subarray *nums[i], nums[i + 1], ..., nums[j]*, there does not exist *i <= k1*, *k2 <= j* with *k1 % n == k2 % n*.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Divide and Conquer	Dynamic Programming	Kadane's Algorithm	Sliding Window	C	**Over-complicated!**<br><br>We divide the array into two, recursively finding the maximum sum subarray in each part. Then, we need to consider the subarrays that cross the midpoint and calculate their sum. The maximum of these three sums would be the maximum sum circular subarray.<br><br>However, a D&C approach would have O(n^2) time complexity and O(n) space complexity!	**Overly complex** compared to other approaches!<br><br>Time Complexity: O(n^2)<br>Space Complexity: O(n)	**Correct!**<br><br>We can first find the maximum subarray sum with Kadane's algorithm, and then the minimum subarray sum using the same algorithm. Then, we can calculate the sum of the entire array.<br><br>The solution then uses these values to calculate the maximum sum subarray in a circular array. If the sum of the entire array equals the minimum subarray sum, then the array has no circular subarray, and the maximum subarray sum is simply the maximum subarray sum found in the linear array. Otherwise, the maximum sum subarray could be a circular subarray, and its sum can be calculated as either the maximum subarray sum, or the difference between the sum of the entire array and the minimum subarray sum.<br><br>Time Complexity: O(n)<br>Memory Complexity: O(1)	This is a **very expensive** window!<br><br>We can calculate the maximum sum subarray that starts from each index, and then calculate the maximum sum subarray that wraps around the array, which can be done by splitting it into two subarrays and calculating their sums using Kadane's algorithm. The maximum of these three sums would be the maximum sum circular subarray.<br><br>This approach would be O(n^2) time and O(1) space.	Iterate through every possible subarray of nums and calculate its sum. Since the array is circular, we can create a new array with size 2*n, where the first n elements are the same as nums, and the last n elements are also the same as nums. Then, for each starting index i (0 <= i < n), we can iterate j (i <= j < i+n), and calculate the sum of nums[i] + nums[i+1] + ... + nums[j]. If the j index goes over n, we can simply subtract n from it to get the corresponding index in the original nums array. We can keep track of the maximum sum we find and return it at the end.<br><br>Although this approach is simple to understand and implement, its time complexity is O(n^2), making it inefficient for large arrays.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Maximum%20Sum%20Circular%20Subarray.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Maximum%20Sum%20Circular%20Subarray.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Maximum%20Sum%20Circular%20Subarray.java	https://youtu.be/cUvIRYS7ktg
Coding Interviews	Arrays: Two Pointers	Two Sum II: Input Array Is Sorted	https://leetcode.com/problems/two-sum-ii-input-array-is-sorted/	Given a **1-indexed array** of integers *numbers* that is already **sorted in non-decreasing order**, find two numbers such that they add up to a specific **target** number. Let these two numbers be *numbers[index1]* and *numbers[index2]* where *1 <= index1 < index2 < numbers.length*.<br><br>Return the **indices of the two numbers**, *index1* and *index2*, **added by one** as an integer array *[index1, index2]* of length 2.<br><br>The tests are generated such that there is exactly **one solution**. You **may not** use the same element twice.<br><br>Your solution must use only **constant extra space**.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Sorting	Floyd's Tortoise And Hare	Kadane's Algorithm + Hash Set	Two Pointers	D	**Suboptimal!**  While this approach is more efficient than the brute force approach, it changes the order of the elements in the array and may not return the original indices of the two numbers that add up to the target.<br><br>Hypothetically, we'd use this method:<br>1) Sort the array.<br>2) Use two pointers: one starting from the beginning of the array, and one starting from the end. Move them towards each other, checking the sum of the values at each pointer.<br>3) If the sum is greater than the target, move the end pointer to the left.<br>4) If the sum is less than the target, move the start pointer to the right.<br><br>Time complexity: **O(n log(n))** due to sorting<br>	Simply, no!	**Why?**<br><br>There's no reason to utilize Kadane's algorithm here: it is reserved for finding the maximum or minimum sums of arrays or subarrays.	**Correct!**<br><br>A two-pointer approach is ideal, since the array is sorted. We initialize one pointer at the beginning of the array (left) and one at the end (right), and then compare the sum of the numbers at the left and right indices with the target value.<br><br>If the sum is less than the target, we move the left pointer to the right to consider a larger number.<br>If the sum is greater than the target, we move the right pointer to the left to consider a smaller number.<br>Finally, if the sum is equal to the target, we return the indices of the two numbers.<br><br>Time Complexity: **O(n)**<br>Space Complexity: **O(n)**, due to the hash table	For each pair of indices *(i,j)* with *i < j*, check if *nums[i] + nums[j] == target*.  This approach is very inefficient since it requires a nested loop to check every possible pair of indices.<br><br>Time complexity is O(n^2)	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Two%20Sum%20II%20-%20Input%20Array%20Is%20Sorted.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Two%20Sum%20II%20-%20Input%20Array%20Is%20Sorted.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Two%20Sum%20II%20-%20Input%20Array%20Is%20Sorted.java	https://youtu.be/zpuu4zQFaDo
Coding Interviews	Arrays: Two Pointers	Move Zeroes	https://leetcode.com/problems/move-zeroes/	Given an integer array *nums*, move all *0*'s to the end of it while maintaining the relative order of the non-zero elements.<br><br>**Note** that you must do this in-place without making a copy of the array.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Copy Array Approach	Count-Based Approach	Linear Pass + Swapping	Two Pointers	D	**Suboptimal!**<br><br>This approach requires an additional array to be created - violating the requirement of doing the operation in-place.	No. **Please re-read the question.**<br><br>This approach violates the requirement of doing the operation in-place!	**Incorrect: this is rather untuitive!**<br><br>This approach results in elements being moved out of order and may result in non-zero elements being moved past other zeros, requiring additional iterations to move them back.	**Correct!**<br><br>In this approach, we use two pointers, start and end, to traverse the array. The start pointer is used to keep track of the current position to place the next non-zero element, while the end pointer is used to traverse the array and find non-zero elements. When a non-zero element is found, it is swapped with the element at the start position, and the start pointer is incremented by 1.<br><br>By the end of the traversal, all non-zero elements have been moved to the front of the array, while the remaining elements are all zeros at the end.<br><br>Time Complexity: **O(n)** since we only traverse the array once.<br>Space Complexity: **O(1)** since we are modifying the input array in-place.	Iterate through the array and for each non-zero element, swap it with the first available zero element after it.<br><br>This approach ensures that all non-zero elements are moved to the front of the array while maintaining their relative order, and all remaining elements at the end of the array are zeroes.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Move%20Zeroes.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Move%20Zeroes.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Move%20Zeroes.java	https://youtu.be/ggKxBuUqCTQ
Coding Interviews	Arrays: Two Pointers	Remove Duplicates From Sorted Array	https://leetcode.com/problems/remove-duplicates-from-sorted-array/	Given an integer array *nums* sorted in **non-decreasing order**, remove the duplicates **in-place** such that each unique element appears only **once**. The **relative order** of the elements should be kept the **same**. Then **return the number of unique elements** in *nums*.<br><br>Consider the number of unique elements of nums to be *k*.  To get accepted, you need to do the following things:<br>1) Change the array *nums* such that the first *k* elements of *nums* contain the unique elements in the order they were present in *nums* initially.  The remaining elements of *nums* are not important, nor is the size of *nums*.<br>2) Return *k*.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Hash Set	Two Pointers	Linear Pass With Deletion	Copy Array Approach	B	**Suboptimal due to the extra memory involved**<br><br>The idea would be to use a hash set to store the unique elements, and then copy the elements back to the original array.<br><br>Although this approach can be implemented in O(n) time, it requires extra memory to store the hash set, which **violates the requirement of doing the operation in-place.**	**Correct!**<br><br>The idea behind this approach is to use two pointers to traverse the array: a slow pointer that points to the last unique element found so far, and a fast pointer that scans the array to find the next unique element.<br><br>If the fast pointer finds a new unique element, it is swapped with the element pointed by the slow pointer, and the slow pointer is moved to the next position.<br><br>Time Complexity: **O(n)**, where n is the length of the input array.<br>Space Complexity: **O(1)**, since you do not use any additional memory to store the unique elements.	**Expensive!**<br><br>We'd be iterating through the array and removing any element that has already been seen.<br><br>This approach would require removing elements from the middle of the array, which is a very costly operation with an array, as all subsequent elements would have to be shifted to fill the gap.	**No.**<br><br>This approach violates the requirement of doing the operation in-place.	We can solve this problem simply by iterating over the array and for each element, checking if it is already in the set.<br><br>If not, then we add it to the set and increment the count of unique elements. At the end, we return the count of unique elements.<br><br>There is a better approach!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Remove%20Duplicates%20from%20Sorted%20Array.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Remove%20Duplicates%20from%20Sorted%20Array.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Remove%20Duplicates%20from%20Sorted%20Array.java	https://youtu.be/4RiJS8ZX0y8
Coding Interviews	Arrays: Two Pointers	Longest Mountain in Array	https://leetcode.com/problems/longest-mountain-in-array/	You may recall that an array *arr* is a **mountain array** if and only if:<br>1) *arr.length >= 3*<br>2) There exists some index *i* (**0-indexed**) with *0 < i < arr.length - 1* such that:<br>a) *arr[0] < arr[1] < ... < arr[i - 1] < arr[i]*<br>b) *arr[i] > arr[i + 1] > ... > arr[arr.length - 1]*<br><br>Given an integer array *arr*, return the **length of the longest subarray, which is a mountain**. Return *0* if there is no mountain subarray.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Two Pointers	Recursion	Sorting + Comparing	Two-Pass Iteration	A	**Correct!**<br><br>This method involves iterating over the array using two pointers, one starting from the beginning of the array and another from the end of the array, and moving them towards each other until they meet at a certain condition.<br><br>In this solution, however, two pointers are not used in the traditional sense. Instead, we have two variables 'up' and 'down' that represent the length of the increasing and decreasing subarrays respectively.<br><br>At each index of the array, we update 'up' and 'down' based on whether the array is still increasing or decreasing. If we encounter a point where the array stops increasing or decreasing, we reset both 'up' and 'down'. Finally, if we find a subarray that is both increasing and decreasing, we calculate the length of this subarray and check if it's the longest so far.<br><br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	**Yikes!**<br><br>This approach would have a time complexity of O(2^n), where n is the size of the array, and would be extremely inefficient - even for moderately sized arrays.	**Incorrect!**<br><br>This approach does not guarantee that the array has a peak element, and therefore may not return the correct answer for arrays that are not mountain arrays.	**Poor** complexity.  This approach involves iterating over the array twice and checking for increasing and decreasing subarrays separately. The idea here isn't bad, although the complexity is horrendous!<br><br>Time Complexity: O(n^2)	Simply check all possible subarrays for the mountain property using nested loops.<br><br>This approach would also have a time complexity of O(n^2), and would not scale well for larger arrays.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Longest%20Mountain%20in%20Array.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Longest%20Mountain%20in%20Array.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Longest%20Mountain%20in%20Array.java	https://youtu.be/Ra4903TWhYw
Coding Interviews	Arrays: Two Pointers	Container With Most Water	https://leetcode.com/problems/container-with-most-water/	You are given an integer array *height* of length *n*. There are *n* vertical lines drawn such that the two endpoints of the *ith* line are *(i, 0)* and *(i, height[i])*.<br><br>Find two lines that together with the x-axis form a container, such that the container contains the most water.<br><br>Return the **maximum amount of water a container can store**.<br><br>**Notice** that you may not slant the container.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Sorting	Dynamic Programming	Two Pointers	Stack	C	**Not quite!**<br><br>The method would involve sorting the array in non-increasing order, and iterating over it to calculate the area between each pair of lines.<br><br>However, this is O(n log(n)) time for the sorting alone, with the subsequent iteration taking O(n) time.	**Whoops!**<br><br>This approach involves calculating the area between each pair of lines and storing it in a 2D array, and is **quite expensive**.<br><br>The idea would be to use DP to calculate the area between all pairs of lines, and return the maximum area seen.<br><br>Time Complexity: O(n^2)	**Correct!**<br><br>We have two pointers: one starting from the beginning of the array and another from the end of the array.  We move them towards each other until they meet at a certain condition, and then calculate the area between them using the formula *(min(height[left],height[right])x(right-left))*.<br><br>We then update the maximum area seen so far if this current area is greater than the previous maximum.<br><br>Whatever the result, we move the pointer that is pointing to the SHORTER line towards the center of the array, as moving the pointer pointing to the taller line towards the center would only result in a decrease in area. We repeat this process until the two pointers meet.<br><br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	**Costly!**<br><br>The theory is that we'd have a stack keep track of the lines, and iterate over the array to calculate the area between each pair of lines.<br><br>This takes O(n) time. However, the subsequent iteration over the stack will take O(n^2) time in the worst case, resulting in a suboptimal solution.	Use nested loops to iterate over all possible pairs of lines and calculate their area, keeping track of the maximum area seen so far.<br><br>This approach has a time complexity of O(n^2), where n is the size of the array. It will result in a time limit exceed error for large arrays.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Container%20With%20Most%20Water.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Container%20With%20Most%20Water.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Container%20With%20Most%20Water.java	https://youtu.be/yiZu5dmfS40
Coding Interviews	Arrays: Two Pointers	3 Sum	https://leetcode.com/problems/3sum/	Given an integer array *nums*, return all the triplets *[nums[i], nums[j], nums[k]]* such that *i != j*, *i != k*, and *j != k*, and *nums[i] + nums[j] + nums[k] == 0*.<br><br>Notice that the solution set must not contain duplicate triplets.	O(n^2)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n^2)**<br>Memory Complexity: **O(n)**<br><br>N.B. this solution is being suggested with a near identical approach to the **Four Sum** problem. Please be aware there are multiple approaches much more efficient than O(n^2)!	Sorting + Binary Search	Two Pointers + Sorting	Simple Mathematics	Dynamic Programming	B	The method looks nice, but the complexity is poor.<br><br>The idea is to sort the array and use binary search to find a third element that would give it a sum of 0.<br><br>Time Complexity: O(n^2 log(n))	Correct!<br><br>This solution is **O(n^2)** since it uses nested loops to iterate over all possible combinations of three numbers.<br><br>However, by sorting the array first, we can optimize the algorithm by using two pointers to traverse the remaining elements of the array. This approach reduces the time complexity from O(n^3) to **O(n^2)**, making the algorithm more efficient.	The method is to generate all triplets with a cleverly designed set of loops, and look for when they sum to zero!<br><br>However, without other data structures, it's going to give us a poor time complexity.	This approach is very convoluted and inefficient!	Simply consider all possible combinations of three numbers from the given array and check if the sum of the three numbers is zero.<br><br>To avoid duplicate triplets, we can sort the array and skip the duplicates while iterating through the array.<br><br>However, this approach has a time complexity of O(n^3) which is not efficient for larger inputs.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/3Sum.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/3Sum.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/3Sum.java	https://youtu.be/ya62BfoD2_M
Coding Interviews	Arrays: Two Pointers	4 Sum	https://leetcode.com/problems/4sum/	Given an array *nums* of *n* integers, return an **array of all the unique quadruplets** *[nums[a], nums[b], nums[c], nums[d]]* such that:<br>1) *0 <= a, b, c, d < n*<br>2) *a*, *b*, *c*, and *d* are distinct.3) *nums[a] + nums[b] + nums[c] + nums[d] == target*<br>4) You may return the answer in **any order**.	O(n^3)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n^3)**<br>Memory Complexity: **O(n)**	Binary Search	Sorting + Nested Loops	Hash Table	Two Pointers + Set + Sorting	D	**Incorrect!**<br><br>Presumably, the idea is that, for each pair of indices *(i,j)*, we use binary search to find two more indices that satisfy the sum condition.<br><br>This approach takes O(n^3 * log(n)) time complexity, which is very slow for larger inputs.	**Incorrect**<br><br>This approach would likely give us (n^3 * log(n)) time complexity, which is not efficient at all.	**Suboptimal** compared to other approaches.<br><br>The idea?  Use a hash table to store all possible pairs of indices (i,j) and their sums, and then iterate over all possible pairs of pairs to find quadruplets that satisfy the sum condition.<br><br>This approach takes O(n^2) extra space, and its time complexity is not optimal either.	**Correct!**<br><br>The idea is to sort the given input array and then use two nested loops to iterate over all possible pairs of elements. For each pair, two pointers are used to scan the remaining array to find two elements such that their sum equals the remainder required to reach the target sum.<br><br>A set is used to store unique quadruplets and avoid duplicates. The elements of any quadruplet found are sorted and then inserted into that set. If the insertion is successful, the quadruplet is added to the final result.<br><br>Time Complexity: **O(n^3)**, where n is the size of the input array.<br>Space Complexity: **O(n)** due to the use of a set to store unique quadruplets.	The brute-force here is very basic: use three nested loops to iterate over all possible quadruplets, and check the sum.<br><br>This approach takes O(n^4) time complexity.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/4Sum.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/4Sum.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/4Sum.java	https://youtu.be/wxxIrIK7gqw
Coding Interviews	Arrays: Two Pointers	Maximum Product of 3 Numbers	https://leetcode.com/problems/maximum-product-of-three-numbers/	Given an integer array *nums*, **find three numbers whose product is maximum** and **return the maximum product**.	O(n log(n))	O(log(n))	We're expecting an optimized solution of:<br>Time Complexity: **O(n log(n))**<br>Memory Complexity: **O(n log(n))**	Sort-Based Approach	Heap-Based Approach	Skinner's Steamed Ham Approach	Hash Table	B	This approach is **suboptimal** because it takes O(n log(n)) time for the sorting and doesn't handle cases where there are negative numbers in the array properly.	**Correct!**<br><br>The solution uses two priority queues (min-heap and max-heap) to keep track of the largest and smallest elements in the array respectively. The code then pops the largest elements from the max-heap and the smallest elements from the min-heap to obtain the three largest and two smallest elements in the array. Finally, it calculates the maximum of the two possible products of these five elements.<br><br>Time Complexity: **O(n log(n))** as it involves sorting the array and performing heap operations.<br>Space Complexity: **O(log(n))** due to the use of priority queues.	**At this time of day, in this part of the country, localized entirely within your computer? May I see it? I don't think it's right, but I guess it could be an Albany expression. Try again!**	The (suboptimal) proposed solution uses a hash table to store the frequencies of each number and then iterates through all possible combinations of three numbers.<br><br>This approach has a time complexity of **O(n^2)**, but may fail when there are more than two negative numbers that produce a larger product when multiplied with a positive number.	Generate all possible combinations of three elements and calculate their product, then return the maximum.<br><br>This approach is suboptimal because it takes O(n^3) time for the combination generation and multiplication, which is too slow for large arrays.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Maximum%20Product%20of%20Three%20Numbers.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Maximum%20Product%20of%20Three%20Numbers.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Maximum%20Product%20of%20Three%20Numbers.java	https://youtu.be/l8hU4MCvjPs
Coding Interviews	Arrays: Two Pointers	Longest Consecutive Subsequence	https://leetcode.com/problems/longest-consecutive-sequence/description/	Given an unsorted array of integers *nums*, return the *length of the longest consecutive elements sequence*.<br><br>You must write an algorithm that runs in *O(n)* time.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Hash Set and Linear Scan	Dynamic Programming	Sort + Linear Scan	Hash Set + Multiple Scans	A	**Correct!**  I've even seen this done using DFS!<br><br>We use a hash set to store the numbers in the input array, and then iterate over the input array to find the starting element of each consecutive subsequence. For each starting element found, the algorithm scans forward in the input array, counting the length of the current consecutive sequence until it ends. The length of each consecutive sequence is compared to the current maximum and the maximum is updated if necessary.<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Hmmmâ€¦this approach would be **O(n^2)** in time complexity. **Do better!**	The sorting operation makes this less efficient than other approaches: it's **O(n log(n))** in complexity!	Technically, yes...but **not the most optimal!**<br><br>A linear scan is enough! This approach would be **O(n)**, but has slightly more memory usage than using a *Hash Set + Linear Scan*.<br><br>You could first count the frequency of each number in a hash table, and then use a hash set to find the longest consecutive sequence.<br>However, this would take two passes over the array, which is O(2n)...well, **O(n)** in memory. However, why do this when we have a more efficient approach?	Iterate through each element in the array, and then check how far it can extend in both directions to form a consecutive sequence.<br>For each element, the BF algorithm would check if the previous or next element is present in the array and keep track of the length of the consecutive sequence.<br>The algorithm would return the maximum length of the consecutive sequence found.<br>However, this approach would have a time complexity of **O(n^3)** as it involves nested loops - it is **not suitable** for solving the problem within the required O(n) time complexity.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Longest%20Consecutive%20Sequence.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Longest%20Consecutive%20Sequence.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Longest%20Consecutive%20Sequence.java	https://youtu.be/-F4Fh9NmM68
Coding Interviews	Arrays: Ad-Hoc	Missing Number	https://leetcode.com/problems/missing-number/	Given an array *nums* containing *n* distinct numbers in the range *[0, n]*, return the **only number in the range that is missing from the array**.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Hash Set	Boolean Array Approach	Gauss Formula	Sort-based Approach	C	**Expensive** in terms of memory.<br><br>The hash set stores the elements of the vector. We can then iterate over the sequence of numbers from 0 to n and check if each number is present in it: finally, we can return the first number that is not found.<br><br>Time Complexity: O(n), where n is the size of the vector.<br>Space Complexity: O(n), as it stores the elements in a hash set.	**Poor** space complexity.<br><br>We create a boolean array of size n+1 and initialize each entry to false. Then, we iterate over the vector, and for each number, set the corresponding boolean element to true. Finally, we iterate over the boolean array and return the index of the first false element.<br><br>Time Complexity: O(n), where n is the size of the vector.<br>Space Complexity: O(n), as it creates a boolean array of size n+1.	**Correct!**<br><br>The **Gauss formula** is used to find the sum of a sequence of numbers - in this case, the sum of numbers from 0 to n. The sum formula is expressed as n*(n+1)/2.<br><br>The solution calculates both the expected sum using the Gauss Sum Formula, AND the actual sum of elements present in the vector. If the expected sum is equal to the actual sum, then no number is missing, and the function returns the size of the vector. Otherwise, it returns the missing number by subtracting the actual sum from the expected sum.<br><br>Time Complexity: **O(n)**, where n is the size of the input vector.<br>Memory Complexity: **O(1)**, as it uses constant space to store the expected sum, actual sum, and size of the vector.	**Not optimal here.**<br><br>This approach has a time complexity of **O(n log(n))**, where n is the size of the vector, due to the sorting process. The algorithm sorts the vector first and then iterates over it to find the missing number. This solution is suboptimal, as it takes longer to execute than the Gauss Formula solution.	Iterate over the vector and check if each number from 0 to n is present in the vector, then return the first number that is not found.<br><br>This approach has a time complexity of O(n^2), where n is the size of the vector.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Missing%20Number.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Missing%20Number.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Missing%20Number.java	https://youtu.be/GrB9SpiHuKI
Coding Interviews	Arrays: Ad-Hoc	Trapping Rain Water	https://leetcode.com/problems/trapping-rain-water/	Given *n* non-negative integers representing an elevation map where the width of each bar is *1*, compute how much water it can trap after raining.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Two Pointers	Greedy Approach	Stack	Dynamic Programming	A	**Correct!**<br><br>In this approach, the code first finds the highest bar's index by iterating over the array once. It then uses two pointers, one from the start and one from the end of the array, to compute the amount of water trapped.<br><br>We iterate from left to right for bars to the **left** of the maximum index, and from right to left for bars to the **right** of the max index.<br>At each iteration, we compute the max height of bars seen so far, and calculate the water trapped.<br>The amount of water trapped is the difference between the max height seen so far and the current height.<br><br>Time Complexity: **O(n)**, where n is the size of the input array, as it makes two passes over the array.<br>Memory Complexity:** O(1)**, as it uses only a constant amount of extra space to store the variables used.	**Too greedy!**<br><br>In the greedy approach, we find the highest bar in the array and calculate the amount of water trapped to its left and right separately.<br><br>This approach is suboptimal because it assumes that the highest bar is the only one that matters when computing the amount of trapped water. This is not necessarily true, as there can be lower bars that form a barrier to water flow and trap more water.<br><br>Time Complexity: O(n)<br>Space Complexity: O(1)	**Suboptimal**.  This requires additional space to maintain the stack, making it less memory efficient. Also, it assumes that the bars form a single basin, which is not necessarily true if there are multiple peaks in the elevation map.<br><br>Method:<br>1) We would iterate over every bar in the array, and maintain a stack of bars that can potentially form a basin.<br>2) When a bar is encountered that can form a basin with the previous bars, calculate the amount of water trapped and add it to the answer.<br><br>Time Complexity: O(n)<br>Space Complexity: O(n)	This approach is suboptimal because it requires additional space to store the precomputed maximum heights, making it less memory efficient.<br><br>Also, it takes longer to set up the precomputed values, which increases the constant factor in the time complexity.<br><br>The idea?<br>1) Precompute the maximum height of bars to the left and right of each bar.<br>)2) Calculate the amount of trapped water for each bar by taking the minimum of the maximum heights and subtracting the height of the bar.<br><br>Time Complexity: O(n)<br>Space Complexity: O(n)	Iterate over every bar in the array, calculating the amount of water trapped between each bar and its adjacent bars, and then add them up.<br><br>The time complexity is O(n^2), and the space complexity is O(1).	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Trapping%20Rain%20Water.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Trapping%20Rain%20Water.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Trapping%20Rain%20Water.java	https://youtu.be/qT4byErCbC0
Coding Interviews	Arrays: Ad-Hoc	Build Array From Permutation	https://leetcode.com/problems/build-array-from-permutation/	Given a **zero-based permutation** *nums* (**0-indexed**), build an array *ans* of the same length where *ans[i] = nums[nums[i]]* for each *0 <= i < nums.length* and return it.<br><br>A **zero-based permutation** *nums* is an array of **distinct** integers from *0* to *nums.length - 1* (**inclusive**).	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Linear Iteration + Swapping	Index Mapping	Hash Table	Sorting	B	This is not quite the right approach.<br><br>It would mean we iterate through the nums array and swap nums[i] and nums[nums[i]] until the array is fully sorted.<br><br>The weakness? This involves repeatedly swapping elements, which can be time-consuming and unnecessary. Additionally, it doesn't guarantee that the resulting array will be the correct answer.	**Correct!**<br><br>In this approach, for each index i, calculate the corresponding index *nums[i]*, and store *nums[i]* in the *i-th* position of the output array *ans*. This can be done by adding *nums[nums[i]] times n to the *i-th* position of nums, then dividing each element of nums by n to get the corresponding element of ans.<br><br>Time Complexity: **O(n)**, where n is the size of the input array.<br>Memory Complexity: **O(1)**, as the output array ans is not stored separately.	This less optimal approach uses a hash table to map each index i in nums to the value of *nums[nums[i]]*. Then, we'd iterate through the nums array and fill in ans[i] with the value mapped to by i in the hash table.<br><br>However, the hash table takes up extra memory space and adds overhead to the algorithm. Additionally, iterating through the nums array and looking up values in the hash table can be **slower than the optimal solution**.	This approach is **suboptimal** because it involves sorting the nums array, which can be time-consuming and unnecessary.<br><br>Additionally, it involves creating a new array, which takes up extra memory space.<br><br>That's the 'why?', here's the 'how?': sort the nums array and create a new empty array ans of length n. For each index i in nums, set ans[i] to nums[nums[i]]. Return the *ans*, but don't use this in your job interview!	Create a new empty array ans of length n. For each index i in nums, set ans[i] to nums[nums[i]], then return ans.<br><br>This approach is suboptimal because it involves creating a new array, which takes up extra memory space. Additionally, it involves iterating through the entire nums array twice, which can be slower than the optimal solution.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Build%20Array%20from%20Permutation.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Build%20Array%20from%20Permutation.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Build%20Array%20from%20Permutation.java	https://youtu.be/GhNvijOIP50
Coding Interviews	Arrays: Ad-Hoc	Next Permutation	https://leetcode.com/problems/next-permutation/	**Simplified problem statement**: find the next **lexicographically greater permutation** of an array of integers, or **arrange it in ascending order** if there is no such greater permutation.<br><br>For example, for *arr* = *[1,2,3]*, the following are all the permutations of *arr*, in lexicographical order: *[1,2,3]*, *[1,3,2]*, *[2, 1, 3]*, *[2, 3, 1]*, *[3,1,2]*, *[3,2,1]*.  The next permutation of *arr* = *[3,2,1]* is *[1,2,3]* because *[3,2,1]* does not have a lexicographical larger rearrangement.<br><br>The **next permutation** of an array of integers is the next lexicographically greater permutation of its integer.  If a lexicographically greater permutation is not possible, the array must be rearranged as the lowest possible order (i.e., sorted in ascending order).<br><br>Given an array of integers *nums*, find the **next permutation** of *nums*.  Perform this task **in place** using constant extra memory.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Sort + Swap	Next Permutation Algorithm	Recursive Approach	Sort Without Swapping	B	**Incorrect!**<br><br>This approach sorts the array in descending order, which isn't necessarily the next permutation. Moreover, the approach fails to find the correct next permutation in cases where there are repeated elements in the array.	**Correct!**<br><br>The method works by:<br>1) Finding the rightmost index *i* such that *nums[i] < nums[i+1]*, indicating that a larger permutation is possible.<br>2) Finding the rightmost index *j* such that *nums[j] > nums[i]*, and swapping the two values.<br>3) Reversing the elements after *i* to produce the **next lexicographically greater** permutation.<br><br>Time Complexity: O(n), where n is the size of the input array.<br><br>Space Complexity: O(1), as the algorithm performs the swaps and reversals in place without using any extra memory.	A **very expensive** operation not required by the problem.<br><br>It also doesn't fulfill the requirement of the problem, which is to implement the algorithm **in place** and using only **constant extra memory**.	This approach is **incorrect** because it doesn't actually find the next lexicographically greater permutation of the array, but rather returns the lowest possible permutation.	Generate all the permutations of the given array, sort them in lexicographical order, and find the next permutation of the given array in the sorted order.<br><br>Unfortunately, generating **all** permutations takes factorial time, which is not efficient for larger arrays.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Next%20Permutation.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Next%20Permutation.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Next%20Permutation.java	https://youtu.be/ZzJeLN_bxYI
Coding Interviews	String	Valid Anagram	https://leetcode.com/problems/valid-anagram/	Given two strings *s* and *t*, return **true** if *t* is an **anagram** of *s*, and **false** otherwise.<br><br>An **anagram** is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once.<br><br>For this instance, let's say we want to include unicode characters - NOT restricting ourselves to lowercase English letters, as in the common version of this problem.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Sort Strings + Check	Count Arrays	Frequency Counting + Hash Tables	Hash Set	C	There are better approaches.<br><br>This particular approach requires sorting both strings, which takes O(n log(n)) time complexity in the worst case. Moreover, it does not use the concept of frequency, which means it may not work for certain cases.	**Poor** in terms of memory complexity!<br><br>The approach is simple: create two arrays of size 26 (one for s and one for t), representing the count of each letter in the strings - then check if the two arrays are equal.<br><br>Although this approach has the same time complexity as the Frequency Counter approach, it requires a fixed-size array of length 26, which means it can't handle strings with characters outside the range of 'a' to 'z'. Additionally, it uses more space than the Frequency Counter approach since the arrays are fixed-size, even if the input strings are small.	**Correct!**<br><br>In our Frequency Counter approach, a frequency table is constructed for each of the input strings, which counts the frequency of each character in the string. Then, the frequency tables of the two strings are compared to check whether they are anagram.<br><br>If the frequency tables match, then the strings are anagrams.<br><br>If any frequency does not match, the strings are not anagrams. If all frequencies match, the strings are anagrams.<br><br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	**Not quite!**<br><br>Here, we'd create a hash set for s and remove each character in t from the set. If the set is empty, s and t are anagrams.<br><br>Although this approach can determine if two strings are anagrams, it requires extra space to store the hash set. It also has a higher time complexity of O(n log(n)) compared to the Frequency Counter approach.<br><br>Additionally, the hash set approach cannot handle cases where a character appears multiple times in either string, while the Frequency Counter approach can handle these cases.	For each character in s, check if it exists in t. If found, remove it from t. At the end, if t is empty, s and t are anagrams.<br><br>This approach has a time complexity of O(n^2), since it involves nested loops, and can be very slow for larger inputs.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Valid%20Anagram.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Valid%20Anagram.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Valid%20Anagram.java	https://youtu.be/wlMoORQcPrk
Coding Interviews	String	Is Subsequence	https://leetcode.com/problems/is-subsequence/	Given two strings *s* and *t*, return **true** if *s* is a subsequence of *t*, or **false** otherwise.<br><br>A **subsequence** of a string is a new string that is formed from the original string by deleting some (can be none) of the characters without disturbing the relative positions of the remaining characters. (i.e., *ace* is a subsequence of *abcde* while *aec* is not).	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Dynamic Programming	Sorting + Binary Search	Simple Linear Search	Two Pointers	D	**Very inefficient.**<br><br>The method? Construct a matrix dp of size (m+1)x(n+1), where m and n are the lengths of s and t, respectively. Initialize the first row and column with zeros. Then, for each i and j, if s[i-1]==t[j-1], set dp[i][j] = dp[i-1][j-1] + 1, otherwise set dp[i][j] = max(dp[i-1][j], dp[i][j-1]). If dp[m][n] == m, return true, otherwise return false.<br><br>This approach has a time complexity of O(mn), and it requires constructing a matrix of size O(mn), which may be memory-intensive. Moreover, this approach may not be optimal for very large inputs.	**Suboptimal.**<br><br>While this approach has a time complexity of O(n log(n)), where n is the length of the longer string t, it requires sorting both strings, which has a time complexity of O(n log(n)) as well. Moreover, this approach doesn't preserve the order of characters in the original string, which violates the requirement that the relative order of characters in s must be preserved in t for s to be considered a subsequence of t.	**Not ideal!**<br><br>The idea is to iterate over each character in s and search for it in t. If found, remove it from t and continue. If all characters in s are found, return true, otherwise return false.<br><br>This approach has a time complexity of O(n^2), where n is the length of the longer string t, because a linear search is performed for each character in s. Additionally, this approach modifies the input string t, which is not allowed in the problem statement.	**Correct!**<br><br>We use two pointers to traverse both strings. The first pointer (ptr1) is used to traverse the shorter string s, while the second pointer (ptr2) is used to traverse the longer string t. At each step, compare the characters pointed to by ptr1 and ptr2. If equal, ptr1 and ptr2 are incremented, and the count of matching characters is incremented. Otherwise, only ptr2 is incremented. The algorithm continues until ptr1 reaches the end of s, or ptr2 reaches the end of t.<br><br>Time Complexity: O(n), where n is the length of the longer string t, since each character in t is only visited once.<br>Space Complexity: O(1), as the only extra space used is for the pointers and the count variable.<br><br>Note that this approach assumes that the characters in both strings are in the same order as they appear in the original string, i.e., the relative order of characters in the shorter string s should be preserved in the longer string t for s to be considered a subsequence of t.	Our brute-force involves generating all possible subsequences of t and check if any of them match s.<br><br>This approach has an exponential time complexity of O(2^n), where n is the length of t, since there are 2^n possible subsequences of t.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Is%20Subsequence.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Is%20Subsequence.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Is%20Subsequence.java	https://youtu.be/rpc1nlhakEM
Coding Interviews	String	Isomorphic Strings	https://leetcode.com/problems/isomorphic-strings/	Given two strings *s* and *t*, **determine if they are isomorphic**.<br><br>Two strings *s* and *t* are isomorphic if the characters in *s* can be replaced to get *t*.<br><br>All occurrences of a character must be replaced with another character while preserving the order of characters. No two characters may map to the same character, but a character may map to itself.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Canonical Mapping	Two Pointers	Sorting	Two Hash Tables	A	**Correct!**<br><br>The method first creates a **canonical mapping** of each character in the string, where each unique character is assigned a unique integer. Then, it compares the canonical mapping of both strings to check if they are equal. If the two strings have the same set of characters, they will have the same canonical mapping, and thus be isomorphic.<br><br>Time Complexity: **O(n)**, where n is the length of the strings, as it iterates over the strings twice, and the unordered_map operations are constant time on average.<br><br>Space Complexity: **O(n)**	This is called the **naÃ¯ve approach** for a reason!<br><br>Naive Two Pointer is suboptimal because it requires O(n^2) time complexity in the worst case, where n is the length of the input strings.<br><br>This approach involves using two pointers to traverse s and t simultaneously. At each step, the algorithm checks if the current character in s is replaced by the current character in t.	**Suboptimal** due to the sorting operation!<br><br>This approach involves sorting the characters in s and t and then checking if the sorted strings are equal. If they are, the strings are isomorphic.	**Poor space complexity.**<br><br>We create two maps, one to store mappings from s to t, and another to store mappings from t to s. Iterate through each character in s and t, and update both maps accordingly. If either map already has an existing mapping for a character, and the mapping is not the same as the current one, return false. Otherwise, return true.<br><br>This approach does not handle the case where multiple characters in s or t map to the same character in the other string.	Check each pair of strings in both s and t to see if they are isomorphic or not.<br><br>To do this, one can compare each character of s to the corresponding character of t and create a mapping of each character in s to the corresponding character in t. Then, for each character in s, check if it maps to the same character in t as it did before. If all characters in s and t are checked and the mappings are the same, then the strings are isomorphic.<br><br>Highly inefficient as a solution!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Isomorphic%20Strings.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Isomorphic%20Strings.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Isomorphic%20Strings.java	https://youtu.be/40pSo2iKBa8
Coding Interviews	String	Verifying an Alien Dictionary	https://leetcode.com/problems/verifying-an-alien-dictionary/	In an alien language, surprisingly, they also use English lowercase letters, but possibly in a different *order*. The *order* of the alphabet is some permutation of lowercase letters.<br><br>Given a sequence of *words* written in the alien language, and the *order* of the alphabet, return **true** if and only if the given *words* are sorted lexicographically in this alien language.	O(nm)	O(k)	We're expecting an optimized solution of:<br>Time Complexity: **O(nm)**<br>Memory Complexity: **O(k)**<br><br>This is really suboptimal for this problem. By far the best is actually to compare adjacent words.<br><br>Let's say the interviewer demands an alternative approach (even if suboptimal). Which is best?	Floyd-Warshall	Create New Strings For Each Word	Hash Table + Order-Based Comparison	Simple Comparison	C	If you selected this, it might be time to learn about the **Floyd-Warshall algorithm**, which is used as a **shortest-paths algorithm**.	This is not a great approach, even compared to the suboptimal 'best of the rest' answer.<br><br>Creating new strings for each word with the corresponding order values and then comparing those strings may not work because it ignores the order of the letters in the words.	**Correct!**<br><br>Our rather imperfect method first creates an hash table to store the order of the alphabet. It then defines a helper function to compare two words based on the order of the characters, and uses this function to compare adjacent words in the input vector to check if they are in the correct order.<br><br>The time complexity of the solution is **O(nm)**, where n is the length of the input vector and m is the maximum length of a word in the vector. The space complexity is**O(k)**, where k is the size of the hash table used to store the order of the alphabet.	Nested loops are rarely the answer<br><br> This approach is suboptimal because it takes O(n^2) time to compare all words with each other, which is much slower than the optimal solution.	Compare each pair of adjacent words in the input list to determine if they are sorted correctly according to the given order of the alphabet.<br><br>First, construct a mapping between each letter in the alphabet and its corresponding position in the given order. Then, iterate through each pair of adjacent words in the input list and compare them character by character. If we find a pair of characters that differ, we would compare their positions in the alphabet using the mapping we constructed earlier.<br><br>If the characters in the first word have a higher position in the alphabet than the characters in the second word, then the words are not sorted correctly, and we can return false immediately. If we have iterated through all pairs of words without finding any that are not sorted correctly, then we can return true.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Verifying%20an%20Alien%20Dictionary.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Verifying%20an%20Alien%20Dictionary.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Verifying%20an%20Alien%20Dictionary.java	https://youtu.be/3unESOkhaf8
Coding Interviews	String	Group Shifted Strings	https://leetcode.com/problems/group-shifted-strings/	We can shift a string by shifting each of its letters to its successive letter.<br>For example, *abc* can be shifted to be *bcd*.<br><br>We can keep shifting the string to form a sequence.<br>For example, we can keep shifting *abc* to form the sequence: *abc -> bcd -> ... -> xyz*.<br><br>Given an array of strings *strings*, group all *strings[i]* that belong to the same shifting sequence. You may return the answer in **any order**.	O(nm)	O(nm)	We're expecting an optimized solution of:<br>Time Complexity: **O(nm)**<br>Memory Complexity: **O(nm)**	Trie-based Grouping	Simple Brute-Force Comparison	Canoncialization + Hash Table	Simpson's Sort	C	Trie? **Try again!**<br><br>In this approach, the student might use a *trie* data structure to group together words that have the same set of characters. They could traverse the trie for each word and add it to the appropriate group.<br>This approach would have a time complexity of *O(nm^2)* and space complexity of *O(nm)*.	**Ouch!**  This would have a time complexity of **O(n^2 m)**, where n is the number of words and m is the maximum length of a word, and a space complexity of O(1).<br><br>Not recommended!	**Correct!**<br><br>The idea is:<br>1) Convert all the strings to their **canonical form** using a simple shifting technique based on the first letter of the string.<br>2) Use a hash table to group together all the strings that have the same canonical form.<br>3) Extract the second part of the hash table, which contains the grouped strings, and return it as a 2D vector.<br><br>Time Complexity: **O(nm)**, where *n* is the number of strings and *m* is the length of the longest string, as we need to iterate over all the strings and perform a single pass over each string to convert it to its canonical form.<br>Space Complexity: **O(nm)**, as we need to store the hash table and the canonical form of each string.	**D'oh!**  Simpson, eh? His sort wouldn't be very useful for this problem...	Iterate through each string in the array, and then iterate through all other strings to check if they belong to the same shifting sequence. This can be done by shifting each character in the string by the same amount and checking if the resulting string exists in the array.<br><br>If a matching string is found, the two strings belong to the same shifting sequence and can be grouped together.<br><br>This process is repeated for all strings in the array to find all the shifting sequences.<br><br>Time Complexity: O(k n^2), where n is the length of the array and k is the length of the longest string.<br>Space Complexity: O(n) to store the resulting groups of strings.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Group%20Shifted%20Strings.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Group%20Shifted%20Strings.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Group%20Shifted%20Strings.java	https://youtu.be/caPHsChN0NQ
Coding Interviews	String	Number of Matching Subsequences	https://leetcode.com/problems/number-of-matching-subsequences/	Given a string *s* and an array of strings *words*, return the number of *words[i]* that is a subsequence of *s*.<br><br>A **subsequence** of a string is a new string generated from the original string with some characters (can be none) deleted without changing the relative order of the remaining characters.<br><br>For example, *ace* is a subsequence of *abcde*.	O(mn)	O(m+n)	We're expecting an optimized solution of:<br>Time Complexity: **O(nm)**<br>Memory Complexity: **O(n+m)**<br>*n* being the length of the string, *m* being the number of words in the given vector<br><br>N.B. there are a few *better* answers in terms of efficiency, such as using a trie.	Character Indexing + Map + Vector	Regex	Greedy Algorithm	Sorting + Binary Search	A	**Correct!**<br><br>Our suggested solution uses an hash table to store the indices of the words starting with each character in the string s.<br><br>Time Complexity: **O(nm)**, where n is the length of the string s and m is the total length of all the words in the vector words.  However, in practice, the time complexity is expected to be lower, especially when there are many distinct characters in the string s compared to the number of words in the vector words.<br>Space Complexity: **O(n+m)**	**Irregular!**<br><br>One could use regular expressions to find the matching subsequences of the given string s in the vector words. While regular expressions can be useful for pattern matching, they can be slow and memory-intensive for large inputs.	**Too greedy!**<br><br>This would involve using some kind of greedy algorithm to find the matching subsequences of the given string s in the vector words. This approach involves selecting the longest matching subsequence at each step, which may not always lead to the optimal solution.<br><br>This approach may work well for some inputs but can fail for others.	**Not really viable here.**<br><br>This approach involves sorting the vector words and using binary search to find the subsequences in the sorted vector. The time complexity of this approach would be *O(m log(m) + n log(n))*, where n is the length of the string s and m is the total length of all the words in the vector words.<br><br>However, binary search can only find exact matches, so this approach may not work if the words in the vector words are not exact subsequences of the given string.	Iterate through each word in the array of words and check if it is a subsequence of the given string s. To check if a word is a subsequence of s, we can iterate through each character of the word and check if it exists in s, maintaining the order of characters. We can keep a count of the number of words that are subsequences of s and return the count at the end.<br><br>The time complexity of this approach is O(nm*max((len(word))), where n is the length of the array of words and m is the length of the given string s.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Number%20of%20Matching%20Subsequences.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Number%20of%20Matching%20Subsequences.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Number%20of%20Matching%20Subsequences.java	https://youtu.be/Sj7gBwpPiYM
Coding Interviews	Matrix	Search a 2D Matrix II	https://leetcode.com/problems/search-a-2d-matrix-ii/	Write an efficient algorithm that searches for a value *target* in an *m x n* integer matrix *matrix*. This matrix has the following properties:<br>1) Integers in each row are sorted in ascending order from left to right.<br>2) Integers in each column are sorted in ascending order from top to bottom.	O(m+n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(m+n)**<br>Memory Complexity: **O(1)**	Convert to Array	Search Space Reduction/Binary Search	Row-Wise Binary Search	Column-Wise Binary Search	B	**No**.  Conversions to arrays rarely work well.<br><br>Here, we'd convert the 2D matrix to a 1D array, perform a binary search to find the target value.<br><br>While this approach may work, it has a space complexity of O(mn) because it requires creating a new array to store all the elements of the matrix. This is inefficient and unnecessary for the given problem.	**Correct!** AKA **Binary Search on 2D Matrix!**<br><br>Start at the top-right corner of the matrix (or bottom-left corner) and compare the value of the element with the target value.  If the target is greater than the current element, then the target value will not be present in that **entire row** because **all elements in that row** are **less than** the current element. Simply move to the next row by incrementing the row index.<br><br>If the target is **less than** the current element, then we can move to the left column by decrementing the column index, because all elements in that column are greater than the current element.<br><br>We repeat this process until either we find the target element or we reach the edge of the matrix.<br><br>Time Complexity: **O(m+n)**, where m and n are the number of rows and columns in the matrix, respectively.<br>Space Complexity: **O(1)**, as the algorithm only requires a constant amount of extra space to store the current row and column indices.	Quite expensive!<br><br>In this, we perform a binary search on each row of the matrix to find the target value.<br><br>While this approach does reduce the search space, it still has a time complexity of O(m log(n)) due to performing binary search on each row, which is less efficient than the optimal solution.	**A little slow.**<br><br>Perform a binary search on each column of the matrix to find the target value.<br><br>This approach still has a time complexity of O(n log(m)) due to performing binary search on each column, which is also less efficient than the optimal solution.	Iterate through every element of the matrix and check if it is equal to the target value.<br><br>This approach has a time complexity of O(mn), which is inefficient for large matrices.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Search%20a%202D%20Matrix%20II.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Search%20a%202D%20Matrix%20II.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Search%20a%202D%20Matrix%20II.java	https://youtu.be/CAwHn0cjtvI
Coding Interviews	Matrix	Rotate Image	https://leetcode.com/problems/rotate-image/	You are given an *n x n* 2D *matrix* representing an image, rotate the image by **90** degrees (clockwise).<br><br>You have to rotate the image **in-place**, which means you have to modify the input 2D matrix directly. **DO NOT** allocate another 2D matrix and do the rotation.	O(n^2)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n^2)**<br>Memory Complexity: **O(1)**	Transpose + Reflect Matrix	Layer by Layer Rotation	Rotate With Simple Swap Operations	Flatten Into Array + Rotate	A	**Correct!**<br><br>First, the **transpose** operation swaps the elements along the main diagonal, i.e., matrix[i][j] is swapped with matrix[j][i]. Then, the **reflection** operation swaps the columns of the matrix, so the first column becomes the last column, the second column becomes the second last column, and so on.<br><br>By applying these two operations in sequence, you can achieve a 90-degree clockwise rotation of the matrix.<br><br>Time Complexity: **O(n^2)**, where n is the size of the matrix.  The transpose operation takes O(n^2) time to perform, and the reflection operation takes O(n^2) time as well.<br>Memory Complexity: O(1) (it's an in-place algorithm!)	Incorrect because it requires **additional memory** to store the layers being rotated, and is more complicated and time-consuming compared to the given approach.	**Incorrect!**<br><br>This only rotates the matrix by 180 degrees, not 90 degrees.	**Incorrect!**<br><br>It requires additional memory to store the one-dimensional array, which is not allowed according to the problem requirements. Additionally, it is less efficient than the given approach since it involves extra copying and conversion steps.	Create a new matrix and copy elements from the original matrix to the new matrix in the rotated positions.<br><br>This approach is incorrect because it requires additional memory to store the new matrix, which is not allowed according to the problem requirements.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Rotate%20Image.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Rotate%20Image.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Rotate%20Image.java	https://youtu.be/DcdOlVZgdhU
Coding Interviews	Stack	Daily Temperatures	https://leetcode.com/problems/daily-temperatures/	Given an array of integers *temperatures* represents the daily temperatures, **return an array** *answer* such that *answer[i]* is the number of days you have to wait after the *ith* day to get a warmer temperature. If there is no future day for which this is possible, keep *answer[i] == 0* instead.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Binary Search	Dynamic Programming	Two Pointers	Monotonic Stack	D	**Not quite correct!**<br><br>Here, for each element in the array, we'd perform a binary search on the rest of the array to find the next warmer day.<br>Time complexity: O(n log(n))<br>Although binary search has a better time complexity than the brute-force approach, it is still not as optimal as the **Monotonic Stack**.  Also, the array is not sorted, which makes it difficult to perform binary search on the rest of the array.	Close, but not quite as good as a monotonic stack.<br><br>The method here?<br>1) We'd traverse the array in reverse order and keep track of the minimum temperature seen so far.<br>2) Calculate the difference between the current temperature and the minimum temperature, and update the result array accordingly.<br>Time complexity: O(n)<br><br>Unlike the Monotonic Stack approach, it requires traversing the array in reverse order, which may not be intuitive or straightforward.	**Suboptimal!**<br><br>The method?<br>1) Use two pointers to traverse the array.<br>2) For each element, move the left pointer to the next warmer day and update the result array.<br><br>Although this approach also has a time complexity of O(n), it does not take advantage of the monotonicity of the temperatures and may not handle certain edge cases properly.	**Correct!**<br><br>This uses a **stack** to track indices of temperatures (temp). We iterate through the array from left to right, checking if the current temp is warmer than the one at the top of the stack.<br>If so, we update the *result* array with the difference between the current index and the stack's top index, indicating the number of days to wait for a warmer temp.  The code allows us to repeat the process until we find a temp that is not warmer than the temp at the top of the stack (or until the stack is empty).<br><br>The stack maintains indices in **non-increasing order**, ensuring temps are always decreasing or constant.  When a warmer temp is found, we pop elements from the stack until we find a temp greater than the current one.<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	For each element in the array, iterate through the rest of the array to find the next warmer day.<br><br>This approach is inefficient because it involves **nested loops**, resulting in a time complexity of *O(n^2)*, which is not optimal for large input sizes.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Daily%20Temperatures.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Daily%20Temperatures.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Daily%20Temperatures.java	https://youtu.be/sXZDeYIlHCc
Coding Interviews	Stack	Next Greater Element II	https://leetcode.com/problems/next-greater-element-ii/	Given a circular integer array *nums* (i.e., the next element of *nums[nums.length - 1]* is *nums[0]*), return the **next greater number** for **every element** in *nums*.<br><br>The **next greater number** of a number *x* is the first greater number to its traversing-order next in the array, which means you could search circularly to find its next greater number. If it doesn't exist, return *-1* for this number.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Hash Table	Sorting	Circular Monotonic Stack	Ingenious Nested Loops	C	A little less optimal than other approaches.<br><br>This approach uses a hash table to store the next greater element for each element. However, it requires iterating over the array multiple times and updating the hash table, which makes it inefficient - and requires extra memory to store the hash table!	**Inefficient.**<br><br>This approach first sorts the array and then iterates over it to find the next greater element for each element.<br><br>Time Complexity: O(n log(n)), due to the sorting operation.	**Correct!**<br><br>Our code shows an approach called **Circular Stack** (or Circular Monotonic Stack), which uses a stack to store the indices of elements in the circular array.  Elements are stored in non-increasing order from the bottom to the top of the stack.<br><br>We traverse the circular array twice. For each element, we pop from the stack until we find an element greater than the current one.<br>If such an element is found, it is assigned as the **next greater element** for the top element of the stack. Otherwise, the top element of the stack is assigned *-1*.<br><br>Time Complexity: **O(n)** as it traverses the circular array twice.<br>Space Complexity: **O(n)** because the size of the stack can go up to n.	There's nothing **clever** about this!<br><br>This approach uses **two nested loops** to iterate over the array and find the next greater element for each element.<br><br>Time Complexity: O(n^2), which is wildly inefficient for large input sizes!	Iterate over the array for each element and find the next greater element by iterating from the next element in a circular manner.<br><br>This approach has a time complexity of **O(n^2)** and is therefore inefficient for large input sizes.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Next%20Greater%20Element%20II.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Next%20Greater%20Element%20II.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Next%20Greater%20Element%20II.java	https://youtu.be/k_zcpOOAS6o
Coding Interviews	Matrix	Range Sum Query 2D	https://leetcode.com/problems/range-sum-query-2d-immutable/	Given a 2D matrix *matrix*, handle multiple queries of the following type:<br>Calculate the sum of the elements of *matrix* inside the rectangle defined by its **upper left corner** *(row1, col1)* and **lower right corner** *(row2, col2)*.<br><br>Implement the *NumMatrix* class:<br>1) *NumMatrix(int[][] matrix)* initializes the object with the integer matrix *matrix*.<br>*int sumRegion(int row1, int col1, int row2, int col2)* returns the **sum** of the elements of *matrix* inside the rectangle defined by its **upper left corner** *(row1, col1)* and **lower right corner** *(row2, col2)*.<br>You must design an algorithm where *sumRegion* works on *O(1)* time complexity.	O(1) for the sumRegion calculation and O(mn) for the constructor	O(mn)	We're expecting an optimized solution of:<br>Time Complexity: **O(1)** for the *sumRegion* calculation, and **O(mn)** for the *constructor*<br>Memory Complexity: **O(mn)**	Prefix Sum By Row	Prefix Sum By Column	2D Prefix Sum	Pre-compute All Submatrix Sums	C	**Far from ideal**.<br><br>Method:<br>1) For each row, create an array of prefix sum and use it to calculate the sum of any subrectangle that has that row as the upper side.<br>2) To calculate the sum for the whole rectangle, iterate over all rows and calculate their contributions.<br><br>Time Complexity: O(mn), and O(m) for each query.  This approach is inefficient since it requires iterating over all rows for each query.	**Inefficient** compared to other approaches.  This approach is inefficient since it requires iterating over all columns for each query.<br><br>Method:<br>1) For each column, create an array of prefix sum and use it to calculate the sum of any subrectangle that has that column as the left side.<br>2) To calculate the sum for the whole rectangle, iterate over all columns and calculate their contributions.<br><br>Time Complexity for initialization is O(mn) and for each query is O(n)	**Correct!**<br><br>The **2D Prefix/Cumulative Sum** calculates the cumulative sum of all elements in the 2D matrix horizontally **and** vertically.<br><br>To achieve **O(1)** time complexity for calculating the sum of the elements of the matrix inside the given rectangle, the cumulative sum of each cell can be used.<br>By calculating the sum of the cells at the four corners of the rectangle and subtracting the cumulative sums of the cells outside the rectangle, the sum of the elements inside the rectangle can be obtained in constant time.<br>The time complexity of the *constructor* is O(mn), where m and n are the dimensions of the matrix.<br>The time complexity of *sumRegion* is O(1), since it only involves simple arithmetic operations.<br>The space complexity is also *O(mn)*, as the cumulative sums are stored in a 2D vector.	**Suboptimal!**  This approach has high initialization time complexity and also requires a lot of extra memory.<br><br>We'd pre-compute all possible submatrice sums with this method:<br>1) Create a 2D array of size *(m+1)x(n+1)* where each element stores the sum of the submatrix from *(0,0)* to *(i,j)*.<br>2) To calculate the sum of a rectangle, use the formula *sum = dp[row2+1][col2+1] - dp[row1][col2+1] - dp[row2+1][col1] + dp[row1][col1]*.<br>The time complexity for initialization is **O(mn^2)** and for each query is **O(1)**.	Iterate over all elements inside the given rectangle and calculate their sum.  This approach is inefficient since it calculates the sum for the same elements multiple times.<br><br>Time Complexity: O(mn), where m is the number of rows and n is the number of columns.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Range%20Sum%20Query%202D%20-%20Immutable.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Range%20Sum%20Query%202D%20-%20Immutable.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Range%20Sum%20Query%202D%20-%20Immutable.java	https://youtu.be/RGG9680fx_Y
Coding Interviews	Matrix	Sparse Matrix Multiplication	https://leetcode.com/problems/sparse-matrix-multiplication/	Given two **sparse matrices** *mat1* of size *m x k* and *mat2* of size *k x n*, return the result of *mat1 x mat2*. You may assume that multiplication is always possible.	O(mnk)	O(mn)	We're expecting an optimized solution of:<br>Time Complexity: **O(mnk)**<br>Memory Complexity: **O(mn)**	Dense Approach: Convert into Dense Matrices	Strassen's Algorithm for Matrix Multiplication	Parallelization	Sparse Matrix Multiplication using Compressed Row Storage (CRS)	D	Not a good idea - a little **dense** perhaps?<br><br>This approach is suboptimal because it does not exploit the sparsity of the input matrices, and it can be very inefficient in terms of time and space complexity for large sparse matrices.	You've **struck out** with **Strassen**, unfortunately.<br><br>While Strassen's algorithm is a fast algorithm for dense matrix multiplication, it is not optimized for sparse matrices. In fact, Strassen's algorithm can **perform worse** than the standard dense matrix multiplication for sparse matrices due to the overhead of recursion.	**Suboptimal for this problem.**<br><br>While parallelization can speed up matrix multiplication for dense matrices, it may not provide significant benefits for sparse matrices.<br><br>In addition, parallelization can introduce additional overhead and synchronization costs that may outweigh the benefits for small to medium-sized matrices.	**Correct!**<br><br>The **CRS algorithm** is based on the observation that if the two matrices mat1 and mat2 are sparse, then most of the entries of the product mat1 x mat2 will be zero. Therefore, instead of performing a full matrix multiplication, we can focus only on the non-zero entries of mat1 and mat2, and compute only the non-zero entries of the product.<br><br>CRS stores the non-zero entries of mat1 in compressed row format, and the non-zero entries of mat2 in uncompressed column format. The algorithm then iterates over the rows of mat1 and multiplies each non-zero entry with the corresponding non-zero entries of the columns of mat2. Since mat2 is stored in column format, it can be accessed efficiently using pointer chasing.<br><br>Time Complexity: **O(mnk)**<br>Space Complexity: **O(mn)**	Simply multiply **each** element of mat1 with element of mat2.<br><br>There is a far more efficient approach!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Sparse%20Matrix%20Multiplication.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Sparse%20Matrix%20Multiplication.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Sparse%20Matrix%20Multiplication.java	https://youtu.be/xao_lOft6hg
Coding Interviews	Stack	Min Stack	https://leetcode.com/problems/min-stack/	Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.<br><br>Implement the *MinStack* class:<br>1) *MinStack()* initializes the stack object.<br>2) *void push(int val)* pushes the element *val* onto the stack.<br>3) *void pop()* removes the element on the top of the stack.<br>4) *int top()* gets the top element of the stack.<br>5) *int getMin()* retrieves the minimum element in the stack.<br><br>You must implement a solution with *O(1)* time complexity for each function.	O(1)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(1)**<br>Memory Complexity: **O(n)**	Two Stacks	Single Stack + Linear Search	Linked List	Stack + Hash Table	A	**Correct!**<br><br>One stack stores all elements, and the other keeps track of the minimum element.  Whenever a new element is pushed onto the stack, if the minimum stack is empty **or** if the new element is less than or equal to the current minimum element, the new element is pushed onto the minimum stack as well.<br><br>Similarly, when an element is popped from the stack, if it is the current minimum element, it is also popped from the minimum stack.<br><br>Time Complexity: **O(1)** for all four operations, push, pop, top, and getMin.<br><br>Memory Complexity: O(n)	**Incorrect!**<br><br>This idea uses a single stack and keep track of the minimum element by iterating over the entire stack every time getMin is called.<br><br>It's suboptimal because it requires O(n) time complexity for the getMin operation, which does not meet the requirement of O(1) time complexity.	**Not ideal.**<br><br>This uses a linked list to implement the stack, with each node storing the element and the minimum element up to that node.<br><br>This approach is suboptimal because it requires additional memory for each node, leading to higher memory usage compared to the Two-Stack Approach.<br><br>The *push*, *pop*, and *top* operations would still require **O(1)** time complexity, but the *getMin* operation would require iterating over the linked list, leading to slower performance compared to the Two-Stack Approach.	**Expensive** in terms of space.<br><br>In this, we maintain an auxiliary data structure (like a hash table) to store the minimum element for every push operation.<br><br>This approach works, but it requires an additional data structure, which takes up **extra space**. Also, updating the auxiliary data structure on every push and pop operation can be time-consuming, making it less efficient than the Two-Stack Approach.	Simply maintain a single stack to store all the elements and an additional variable to store the minimum element.<br><br>On every *push* operation, compare the new element with the minimum element, and if the new element is smaller, update the minimum variable. Similarly, on every *pop* operation, check if the popped element is the minimum element and update the minimum variable accordingly.<br><br>For the *getMin()* operation, simply return the minimum variable.<br><br>However, this approach is not optimal as it requires additional comparisons on every push and pop operation, which can increase the time complexity beyond O(1). <br><br>In addition, the minimum variable can become invalid if the minimum element is popped.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Min%20Stack.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Min%20Stack.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Min%20Stack.java	https://youtu.be/Ad_EqZEgj8Q
Coding Interviews	Stack	Simplify Path	https://leetcode.com/problems/simplify-path/	Convert an **absolute path** (starting with a slash */*) represented by a string *path* to its simplified **canonical form path** in a Unix-style file system.<br><br>Remove any redundant periods (*.* or *..*), consecutive slashes (*//*), and trailing slashes (*/*) from the result.<br><br>The **canonical path** should:<br>1) Start with a single slash */*<br>2) Only contain valid directory names separated by a single slash.<br>3) Not end with a trailing slash.<br><br>N.B. Click on the LeetCode link for an expanded problem statement.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Regex	Stack	Two Linear Scans	Recursive Approach	B	Not the 'regular' approach - nor the best of the options here.<br><br>Regular expressions can match and remove segments in the input path. While true, and this approach would have a time complexity of O(n), it could be difficult to implement and may not be as efficient as the 'stack'-based approach. (Our approach utilised a vector which behaves like a stack).	**Correct!**<br><br>We use a vector that 'behaves' like a stack in our approach, along with a function *split* to take the input along with a separator character */*, which returns a vector of strings representing the substrings between the separators.<br><br>*simplifyPath* uses *split* to ummm...split the input path into **tokens**, and then uses a stack to keep track of the current path as it processes each token. If a token is empty or *.*, it is ignored. If a token is *..*, the function pops the last element from the stack (if there is one). Otherwise, the token is pushed onto the stack.<br><br>If the stack is empty, the function returns */*.  Otherwise, it concatenates the elements of the stack with / and returns the resulting string.<br><br>Time Complexity: O(n)<br>Memory Complexity: O(n)	**Expensive!**<br><br>We'd store segments in a collection after the first pass, and then simplify each segment in a second pass.<br><br>This approach would have a time complexity of O(n) in the best case, but could potentially have a worst case time complexity of O(n^2) if the input path contains many unnecessary segments.	So, you want to call the simplifyPath function recursively on each segment of the input path, and then combine the results?<br><br>It's really the **worst idea** here, for many reasons!<br><br>This approach would have a time complexity of O(2^n) in the worst case, where n is the number of segments in the input path.	Split the input string *path* by slashes to get all the directories and file names. Loop through each directory/file name and build a new path by appending each of them to the previous directory, while checking for any special cases such as periods or double periods.<br><br>For example, if the input path is */a//b/c/.././d*, we can split it into *[,a,,b,c,..,.,d]*. We can then loop through this array and build the simplified **canonical path**, which would be **/a/b/d**, as outlined above.<br><br>However, this approach is not optimal, as it requires additional comparisons and loops to check for special cases and append each directory and file name, which increases the time complexity beyond the required O(n).	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Simplify%20Path.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Simplify%20Path.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Simplify%20Path.java	https://youtu.be/DirShFDYEuY
Coding Interviews	Stack	Largest Rectangle in Histogram	https://leetcode.com/problems/largest-rectangle-in-histogram/	Given an array of integers *heights* representing the histogram's bar height where the width of each bar is *1*, return the **area of the largest rectangle in the histogram**.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Divide and Conquer	Dynamic Programming	Sorting + Comparing	Monotonic Stack Algorithm	D	**Too complicated!**<br><br>With D&C, we'd divide the histogram into two halves and find the maximum area for each half recursively.<br><br>This approach has a time complexity of O(n log(n)) in the worst case, but it requires **extra implementation complexity** and may not be as intuitive for some programmers. Additionally, it may not perform well in cases where the maximum area involves bars that span both halves of the histogram.	**Slow!**<br><br>Method:<br>1) Use dynamic programming where dp[i] represents the maximum area that can be formed using bars from 0 to i.<br>2) For each i, we'd iterate backwards from i to 0 to find the leftmost bar j such that *heights[j] < heights[i]* and find the rightmost bar k such that *heights[k] < heights[i]*.<br>3) The maximum area for bar i is *(k - j - 1) X heights[i]* and the maximum area that can be formed using bars from 0 to i is the maximum of *dp[i-1]* and the area for bar i.<br>4) Finally, we update dp[i] with the maximum area found so far.<br><br>Time Complexity: O(n^2) in the worst case, which will time out on large inputs.	**Poor** in terms of time and memory.<br><br>Method:<br>1) Sort the histogram in non-decreasing order of heights.<br>2) Iterate through the sorted histogram, for each bar i, find the leftmost bar j such that *heights[j] < heights[i]* and find the rightmost bar k such that *heights[k] < heights[i]*.<br>3) The maximum area for bar i is *(k - j - 1) X heights[i]*. Update the maximum area found so far.<br><br>Time Complexity: O(n^2)	**Correct!**<br><br>Our algorithm calculates the next smaller element (NSE) and previous smaller element (PSE) for each element in the given array using a *stack*. The NSE for an element is the closest element on the right that is smaller than it, and the PSE is the closest element on the left that is smaller than it. After getting these two arrays, we iterate through the array and calculate the area of the rectangle for each element using the formula *height X (right - left + 1)*, where *height* is the height of the current element, *left* is the index of the previous smaller element + 1, and *right* is the index of the next smaller element - 1. Finally, the algorithm returns the maximum area calculated.<br><br>Time Complexity: O(n), where n is the size of the input array.<br>Space Complexity: O(n)	Iterate through all possible rectangles in the histogram and calculate the area of each one.<br><br>Use two nested loops where the outer loop will iterate through each bar in the histogram, and the inner loop will iterate from the current bar to the end of the histogram.<br>For each pair of bars (i, j) where i <= j, we can calculate the area of the rectangle formed by these bars by multiplying the minimum height between them by the width (j-i+1).<br>We can keep track of the maximum area we find as we iterate through the histogram.<br>The time complexity of this approach is O(n^2), where n is the number of bars in the histogram.<br>The space complexity is O(1) as we are not using any extra space besides the input histogram array.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Largest%20Rectangle%20in%20Histogram.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Largest%20Rectangle%20in%20Histogram.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Largest%20Rectangle%20in%20Histogram.java	https://youtu.be/4T3W8tvusmU
Coding Interviews	Stack	Maximal Rectangle	https://leetcode.com/problems/maximal-rectangle/	Given a *rows x cols* binary *matrix* filled with *0*'s and *1*'s, find the largest rectangle containing only *1*'s and **return its area**.	O(nm)	O(nm)	We're expecting an optimized solution of:<br>Time Complexity: **O(mn)**<br>Memory Complexity: **O(mn)**	DFS	Prefix Sum + Monotonic Stack	Dynamic Programming	Recursive Approach	B	**Yikes!**<br><br>This approach would also have a horrible time complexity, because there are O(n^2) cells in the matrix and each DFS takes O(n^2) time in the worst case. Additionally, this approach would use O(n^2) space for the visited array.	Correct!<br><br>The solution converts the input binary matrix to a 2D vector of integers, where each cell stores the length of the maximum consecutive 1's in the same column up to that row. It iterates over each column, incrementing the cell value if it's a 1, similar to a prefix sum for columns. <br><br>Next, it computes the largest rectangle containing only 1's for each row using next/previous smaller element (NSE/PSE) arrays and a stack-based approach. NSE and PSE store the indices of the next smaller element on the right and left. These arrays are computed by maintaining a stack of increasing elements while iterating over the heights vector. For each row, it calculates the area of the rectangle with the current height using NSE/PSE arrays. The maximum area across all rows is returned as the solution.<br><br>Time Complexity: O(mn)<br>Memory Complexity: O(mn)	Incorrect approach.<br><br>DP computes the area of the largest rectangle containing only 1's that ends at each cell in the matrix, returning the maximum area found.<br><br>This approach does not take into account the fact that the largest rectangle may not end at each cell. It is possible for a larger rectangle to include cells that were not included in any of the previous rectangles computed.	Inefficient, as this would require a lot of repeated computation.<br><br>The basic idea is to use a recursive approach where for each cell containing a 1, calculate the largest rectangle that can be formed with that cell as the top-left corner. We then keep track of the maximum area seen so far and return it.<br><br>Time Complexity: O(rows^2 cols^2), which is very slow for larger inputs.	Iterate over all submatrices and check if each one contains only 1's. We then return the area of the largest rectangle found.<br><br>This approach would have a very poor time complexity!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Maximal%20Rectangle.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Maximal%20Rectangle.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Maximal%20Rectangle.java	https://youtu.be/jdpDkNkjpUw
Coding Interviews	Stack	Largest Submatrix With Rearrangements	https://leetcode.com/problems/largest-submatrix-with-rearrangements/	You are given a binary matrix *matrix* of size *m x n*, and you are allowed to rearrange the **columns** of the *matrix* in any order.<br><br>Return the **area of the largest submatrix** within *matrix* where **every** element of the submatrix is *1* after reordering the columns optimally.	O(mn*log(n))	O(mn)	We're expecting an optimized solution of:<br>Time Complexity: **O(mnlog(n))**<br>Memory Complexity: **O(n)**	Greedy Rearrangement	Row Sorting + Histogram	Prefix Sum + Monotonic Stack	Random Rearrangement	C	**Not quite right.**<br><br>We could greedily rearrange the columns by first moving columns with the most ones to the left, followed by columns with fewer ones.<br><br>This approach is incorrect because it may not always result in the optimal rearrangement of the columns.	This approach is **incorrect** because sorting the rows will not cluster the ones together in a way that helps us compute the maximum area of a submatrix.	**Correct!**<br><br>The idea is to first compute the column-wise prefix sums of the binary matrix. Then, for each row in the matrix, sort the columns in ascending order of their prefix sums.  Finally, we can compute the maximum area of a histogram for each row of the sorted matrix using the Next Smaller Index and Previous Smaller Index methods.<br><br>Time Complexity: O(mn log(n)), where m is the number of rows and n is the number of columns - and we need to sort each row of the matrix, which takes O(n log(n)) time.<br>Space Complexity: O(n), which is the size of the vector used to store the column-wise prefix sums.	Hmmmâ€¦this approach is **incorrect** because it may not always find the optimal arrangement of the columns, and may require a large number of random rearrangements to converge to the optimal solution.	Enumerate all possible submatrices of the binary matrix and check if each submatrix is made up entirely of ones.<br><br>This approach is incorrect has dreadful time complexity.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Largest%20Submatrix%20With%20Rearrangements.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Largest%20Submatrix%20With%20Rearrangements.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Largest%20Submatrix%20With%20Rearrangements.java	https://youtu.be/BPQ-IPJ7QWo
Coding Interviews	Stack	Maximal Square	https://leetcode.com/problems/maximal-square/	Given an *m x n* binary *matrix* filled with *0*'s and *1*'s, **find the largest square** containing only *1*'s and **return its area**.	O(nm)	O(nm)	We're expecting an optimized solution of:<br>Time Complexity: **O(mn)**<br>Memory Complexity: **O(mn)**	DFS or BFS	DP or Monotonic Stack	Bogan's Brute Force or Failure	Greedy	B	Seriously **poor** time complexity.<br><br>The idea is very simple:<br>Find all squares that contain only 1's.  Start at each cell containing a 1, and explore all adjacent cells to see if they form a square.<br><br>Time Complexity: O(NOT GOOD)!	**Correct!**  Our code is showing a stack-based approach here.<br><br>This technique is a common approach when solving matrix-related problems, and can be used to solve various problems such as the maximum sum submatrix and longest common submatrix.<br>We just calculate the maximum area of a square that ends at each position in the matrix.<br><br>Time Complexity: O(mn)<br>Memory Complexity: O(mn)	Too **naÃ¯ve**!<br><br>The time complexity of this approach would be O(m^2 n^2), since you would need to check each cell and then potentially expand a square of size O(min(m, n)) in all four directions.	Don't be **greedy** (with your approach) here!<br><br>The method?<br>1) Start at the top left corner and greedily expand a square as far as possible to the right and downwards.<br>2) Once you hit a zero, move to the next row and start again from the leftmost column. Keep track of the largest square at each point.<br><br>Time Complexity: O(nm)â€¦in the best case! In the worst case (e.g. a matrix that is comprised entirely of 1's) it could be as bad as **O(m^2n)**!	Iterate through all possible squares in the matrix and check if they are all filled with 1's. This would involve going through each cell in the matrix and checking if the cell and its neighbors form a square filled with 1's.<br><br>If a square is found, its area is compared to the current maximum area and updated accordingly. This approach has a **horrible** time complexity, making it inefficient for large matrices.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Maximal%20Square.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Maximal%20Square.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Maximal%20Square.java	https://youtu.be/Mu16nnYPYN8
Coding Interviews	Stack	Exclusive Time of Functions	https://leetcode.com/problems/exclusive-time-of-functions/	Given a list *logs* representing logs of **function calls** and their timestamps, calculate the **exclusive time** for each function in a **single-threaded** CPU program. The *logs* list contains strings in the format *{function_id}:{start | end}:{timestamp}*.<br><br>The exclusive time is the **total execution time of each function**, considering **recursive calls**.<br><br>Return an array where the value at the *ith* index represents the **exclusive time** for the function with ID *i*.<br><br>Click on the LeetCode link for a more detailed problem statement!	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Recursive	Stack	Hash Table	Brute Force Approach	B	A little inefficient!<br><br>Method:<br>Use recursion to traverse the call stack, computing the exclusive time for each function.<br><br>Weakness:<br>This is inefficient because it requires multiple traversals of the call stack, which increases the time complexity. Recursion is neither optimal nor necessary when solving this problem.	**Correct!**<br><br>Our stack keeps track of the function calls in a log.<br><br>Method:<br>1) We extract three things from each log: the *function ID*, whether it is a *start* or *end* call, and the *timestamp*.<br>2) If it's a *start* call, a new entry is pushed onto the stack. Otherwise, the top entry is popped and we calculate the total execution time (TET).<br>3) The exclusive execution time (EET) for the current function is calculated by subtracting the sub-call time of the current function from the TET.<br>4) The sub-call time is the TET of all child functions that were called within the current function.<br>5) The EET is added to the result array for the ID that we extracted.<br>6) Finally, the sub-call time for the parent function is updated by adding the TET of the current function.<br><br>Time Complexity: O(n), where n is the number of logs in the input vector, with each log message being processed precisely once.<br>Space Complexity: O(n), where n is the number of functions.	**A little inefficient!**<br><br>Method:<br>Use a dictionary to store the start and end times for each function, and then compute the exclusive time for each one.<br><br>Weakness:<br>Compared to a stack-based approach, this requires extra space to store the dictionary.<br><br>Time Complexity: O(n log(n)), where n is the number of functions.<br>Space Complexity: while useful for storing the start and end times for each function, a dictionary is not necessary, requiring additional space complexity as well.	**Not ideal at all!**<br><br>Method:<br>The program iterates over all function calls, but optimizes the computation of exclusive time by skipping unnecessary calls.<br><br>Weakness:<br>This approach has a time complexity of O(n^2), where n is the number of functions.<br><br>The minor optimization is not sufficient to overcome the inefficiency of iterating over all possible function calls.	Iterate over all possible function calls and compute the exclusive time for each one using some nested loops.<br><br>This approach is inefficient - find a way without nested loops!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Exclusive%20Time%20of%20Functions.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Exclusive%20Time%20of%20Functions.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Exclusive%20Time%20of%20Functions.java	https://youtu.be/56R0bOZKotI
Coding Interviews	Stack	Longest Valid Parentheses	https://leetcode.com/problems/longest-valid-parentheses/	Given a string containing just the characters *'('* and *')'*, return the **length of the longest valid (well-formed) parentheses** substring.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Stack	Two Stacks	Count-Based Approach	Dynamic Programming	A	**Correct!**<br><br>This solution uses a stack to keep track of indices of opening brackets *(* encountered. The stack initially has *-1* as the base.<br><br>The code then iterates through the given string and checks for opening brackets, pushing their indices onto the stack. When it encounters a closing bracket *)*, it pops the top of the stack. If the stack is empty, it means no opening bracket was found to match the current closing bracket, and the closing bracket index is pushed onto the stack as the new base.<br><br>If the stack is not empty, the length of the valid parentheses substring is computed by taking the difference between the current index and the index at the top of the stack. The maximum length seen so far is kept as the final result.<br><br>Time Complexity: O(n)<br>Memory Complexity: O(n)	Unnecessarily **complex**!<br><br>We could create two stacks, one for opening parentheses and one for closing parentheses. Then, we'd iterate through the string, pushing opening parentheses onto the opening stack and closing parentheses onto the closing stack.<br><br>If the top elements of both stacks are of equal distance from the start of the string, pop them both and update the maximum length seen so far. Finally, we return the maximum length seen.	**Suboptimal** because it does not account for the case where the valid parentheses substring is nested within another one.<br><br>For example, in the string *(()())*, the valid parentheses substring is *()()*, but the counting method would only detect the first pair of parentheses.	This is simply **over-engineering** the solution to the problem here.	Generate all possible substrings of the given string and check if each substring is valid or not. To check if a substring is valid, we can use a stack to keep track of opening brackets and pop from the stack whenever we encounter a closing bracket.<br><br>If the stack becomes empty, then the substring is valid. We can keep track of the length of the longest valid substring found so far and return it at the end.<br><br>The time complexity of this approach is O(n^3) since we need to generate all possible substrings and check each of them.<br><br>This approach is inefficient and not suitable for large input strings.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Longest%20Valid%20Parentheses.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Longest%20Valid%20Parentheses.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Longest%20Valid%20Parentheses.java	https://youtu.be/tYpZ2sYLePU
Coding Interviews	Priority Queue	Kth Largest Element in an Array	https://leetcode.com/problems/kth-largest-element-in-an-array	Given an integer array *nums* and an integer *k*, return the *kth* **largest element in the array**.<br><br>Note that it is the *kth* largest element in the sorted order, not the *kth* distinct element.	O(n log(k))	O(k)	We're expecting an optimized solution of:<br>Time Complexity: **O(n log(k))**<br>Memory Complexity: **O(k)**	Sort-Based Approach	Sorting + Binary Search	Max-Heap	Min-Heap	D	Sorting takes **O(n log(n))** time complexity, which is suboptimal as per the problem requirements.	**Suboptimal!**<br><br>Sorting takes O(n log(n)) time complexity, which is slower than the required O(n) time complexity.	**Suboptimal.**<br><br>Creating a max-heap and removing k-1 elements takes O(n log(n)) time complexity, which is not optimal as per the problem requirements.	**Correct!**<br><br>Our code uses the**Kth Largest Element in a Stream** approach, with a min-heap storing the top k elements of the array.<br><br>The heap is initially empty, and as elements are processed from the array, they are either<br>1) ignored if they are smaller than the top of the heap (i.e., not one of the k largest elements seen so far)<br>2) inserted into the heap with the smallest element is removed if the heap size exceeds k.<br><br>Once all elements have been processed, the top of the heap is the kth largest element in the array.<br><br>Time Complexity: O(n log(k))<br>Space Complexity: O(k), as the heap contains at most k elements.	Sort the array in descending order and return the kth element.<br><br>The time complexity of this approach is O(n log(n)) due to the sorting algorithm used, where n is the size of the array.<br>The space complexity is O(1) as the sorting is performed in place.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Kth%20Largest%20Element%20in%20an%20Array.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Kth%20Largest%20Element%20in%20an%20Array.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Kth%20Largest%20Element%20in%20an%20Array.java	https://youtu.be/xvvo4GVQq3c
Coding Interviews	Priority Queue	K Closest Points To Origin	https://leetcode.com/problems/k-closest-points-to-origin/	Given an array of *points* where *points[i] = [xi, yi]* represents a point on the **X-Y** plane and an integer *k*, return the *k* closest points to the origin *(0, 0)*.<br><br>The distance between two points on the **X-Y** plane is the Euclidean distance (i.e., *âˆš(x1 - x2)^2 + (y1 - y2)^2*).<br><br>You may return the answer in **any order**. The answer is **guaranteed** to be **unique** (except for the order that it is in).	O(n log(k))	O(k)	We're expecting an optimized solution of:<br>Time Complexity: **O(n log(k))**<br>Memory Complexity: **O(k)**	Sort-Based Approach	Min-Heap	Max-Heap	Binary Search	C	**Suboptimal** due to the sorting.<br><br>Sorting the points by distance from the origin would have a time complexity of O(n log(n))<br><br>This would also require extra memory to store the sorted array.	The **max-heap is better** for this famous problem!	**Correct!**<br><br>A max-heap is used to maintain the k-closest points. Initially, the first k points are pushed onto the max heap.<br><br>For each subsequent point, its distance from the origin is calculated and compared with the maximum distance in the max heap. If the distance of the current point is less than the maximum distance in the max-heap, then this point is added to it and the point with the maximum distance is removed.<br><br>Finally, the K-closest points are extracted from the max-heap in descending order of distance and returned.<br><br>Time Complexity: O(n log(k)), where n is the number of points in the input and k is the number of closest points to be found. This is due to the use of a max heap with size k, which has an insertion time of log(k) and the loop to iterate through all points.<br>Space Complexity: O(k), as we are only storing the k-closest points in the max heap.	**Not applicable** since there is no sorted order to the distances.	Calculate the distance from each point to the origin, store the distances and their corresponding points in a vector of pairs, sort the vector in ascending order by the distances, and return the first k elements of the sorted vector.<br><br>This approach has a time complexity of O(n log(n)) due to the sorting operation, and a space complexity of O(n) to store the distances and points.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/K%20Closest%20Points%20to%20Origin.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/K%20Closest%20Points%20to%20Origin.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/K%20Closest%20Points%20to%20Origin.java	https://youtu.be/_myUjnGPCF8
Coding Interviews	Priority Queue	Maximum Performance of a Team	https://leetcode.com/problems/maximum-performance-of-a-team/	You are given two integers *n* and *k* and two integer arrays *speed* and *efficiency*, both of length *n*. There are *n* engineers numbered from *1* to *n*. *speed[i]* and *efficiency[i]* represent the speed and efficiency of the *ith* engineer respectively.<br><br>Choose at most *k* different engineers out of the *n* engineers to form a team with the maximum performance.<br><br>The performance of a team is the sum of their engineers' speeds multiplied by the minimum efficiency among their engineers.<br><br>Return the **maximum performance of this team**. Since the answer can be a huge number, return it **modulo** 1e9 + 7.	O(n log(n))	O(log(k))	We're expecting an optimized solution of:<br>Time Complexity: **O(n log(n))**<br>Memory Complexity: **O(log (k))**	Greedy Algorithm + Priority Queue	Selection Sort	Dynamic Programming	Bogan's Brute Force Approach	A	**Correct!**<br><br>Our method sorts the engineers in decreasing order of efficiency, then uses a priority queue to keep track of k best speed values encountered so far.<br>It then adds the speeds of engineers one by one to the queue, and calculates the maximum performance of the team at each step by taking the sum of speeds from the queue and multiplying it with the efficiency of the current engineer.<br>The maximum performance seen so far is updated with the new value if necessary.<br><br>Time Complexity: **O(n log(n))**<br><br>Memory Complexity: **O(log(k))**	You've made an **incorrect** selection here!<br><br>This approach would struggle to consider the efficiency of the engineers and may not result in calculating the maximum performance of the team.	An **over-engineeered** approach: ironic, given the problem statement!<br><br>This would use DP to calculate the maximum performance for every possible combination of engineers and choose the best k.<br><br>However, it has a time complexity of **O(2^n)**, which is exponential, making it unfeasible for large values of n.	**Impractical**<br><br>This approach has an exponential time complexity and is not feasible for large values of n and k.	Generate all possible combinations of teams by selecting at most k engineers from the n available, computing the performance of each team and returning the maximum performance obtained.<br><br>One way to implement this uses nested loops to generate all possible combinations of k engineers out of n, and then iterate through each team, computing their performance and keeping track of the maximum performance seen so far.<br><br>Time Complexity: O(n^k), which is exponential, and completely impractical for large values of *n* and *k*!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Maximum%20Performance%20of%20a%20Team.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Maximum%20Performance%20of%20a%20Team.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Maximum%20Performance%20of%20a%20Team.java	https://youtu.be/okVJQQPDK7A
Coding Interviews	Priority Queue	Maximum Number of Events	https://leetcode.com/problems/maximum-number-of-events-that-can-be-attended/	You are given an array of *events* where *events[i] = [startDayi, endDayi]*. Every event *i* starts at *startDayi* and ends at *endDayi*.<br><br>You can attend an event *i* at any day *d* where *startTimei <= d <= endTimei*. You can only attend one event at any time *d*.<br><br>Return the **maximum number of events you can attend**.	O(n log(n))	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n log(n))**<br>Memory Complexity: **O(n)**	Sort By Earliest End Time	Burari Random Approach	Min-Heap	Sort by Earliest Start Time	C	**Incorrect**<br><br>Sorting by end time only takes into account the duration of events and not their start times, which can lead to missing out on events that have a later end time but a shorter duration, and a later start time.	**No such algorithm exists** (*at the time of writing*)!<br><br>Randomly attending is incorrect because it does not take into account the duration or timing of events, which can lead to missing out on events that have a shorter duration or start later, but have an earlier end time.	**Correct!**<br><br>A good approach uses a min-heap to keep track of the events' end days, and using this algorithm:<br>1) Sort the events by their start day.<br>2) Loop through each day from day 1 until all events are processed.<br>3) Remove the events that have ended before the current day from the heap.<br>4) If there are no available events and there are more events left, jump to the next event start day.<br>5) Add all events that start on the current day to the heap.<br>6) Attend the event with the earliest end day from the heap.<br><br>Time Complexity: **O(n log(n))**<br>Memory Complexity: O(n)	**Incorrect**<br><br>Attending events in order of start time only takes into account the order in which events begin, and not their duration or end times, which can lead to missing out on events that have a later start time but an earlier end time.	Generate all possible combinations of events and count the number of valid combinations.<br><br>To generate all possible combinations, one could start with the first event and then recursively add the next event that does not overlap with any of the events already chosen.<br><br>For each valid combination, the count of events attended can be computed and compared to the maximum count seen so far.<br><br>The time complexity is O(2^n) where n is the number of events, since there are 2^n possible combinations - clearly impractical for large values of *n*.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Maximum%20Number%20of%20Events%20That%20Can%20Be%20Attended.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Maximum%20Number%20of%20Events%20That%20Can%20Be%20Attended.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Maximum%20Number%20of%20Events%20That%20Can%20Be%20Attended.java	https://youtu.be/QWo_I3Td4rs
Coding Interviews	Priority Queue	Sliding Window Maximum	https://leetcode.com/problems/sliding-window-maximum/	You are given an array of integers *nums*, there is a sliding window of size *k* which is moving from the very left of the array to the very right. You can only see the *k* numbers in the window. Each time the sliding window moves right by one position.<br><br>Return the **max sliding window**.	O(n)	O(k)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(k)**<br><br>n is the the number of elements in the input arrayâ€¦I'll let you work out k!	Two Loops	Max-Heap	Bogan's Brute Force	Deque	D	**Highly impractical!**<br><br>This would use a simple for-loop to iterate through the array, and use another loop to find the maximum value in the current sliding window.<br><br>Overall, the approach would have a time complexity of O(n*k) and would be highly inefficient for large inputs.	**Poor space complexity!**<br><br>We could use a max-heap to store the elements in the current sliding window and update it every time the window moves. However, this approach would require a lot of memory to store the heap and would not be optimal for very large inputs.<br><br>In addition, the time complexity of updating the heap every time the window moves would also be high.	People named Bogan are rarely the best people to ask!<br><br>This approach creates all possible sliding windows and finds the maximum value for each one. It would have a time complexity of O(n^2) and would be highly inefficient for even moderately sized inputs.	**Correct!**<br><br>In this method, we use a **deque** to store the indices of the elements in the current window, such that the deque is always in decreasing order of the values of elements in the window. Thus, the first element entered into it will always be the maximum value in the current window.<br><br>At each step, we check if the first element of the deque is outside the current window. If it is, it's removed from the deque.<br><br>We then remove all elements from the back of the deque that are smaller than the current element.  Finally, we add the current element to the back of the deque. If the current index is greater than or equal to k-1, then the maximum value for the current window is the first element of the deque, which you add to the result vector.<br><br>Time Complexity: **O(n)**<br>Memory Complexity: **O(k)**	Iterate through the array and for each position, consider the sliding window of size k starting from that position, and find the maximum element in the window.<br><br>Repeat this process for all possible starting positions of the sliding window and return the maximum elements found.<br><br>This approach would have a time complexity of O(nk) since for each position we are iterating over a window of size k to find the maximum element.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Sliding%20Window%20Maximum.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Sliding%20Window%20Maximum.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Sliding%20Window%20Maximum.java	https://youtu.be/qvuFPjmq6Ro
Coding Interviews	Priority Queue	Find Median from Data Stream	https://leetcode.com/problems/find-median-from-data-stream/	The **median** is the middle value in an ordered integer list. If the size of the list is even, there is no middle value, and the median is the mean of the two middle values.  Some examples include:<br>1) *arr = [2,3,4]*, where the median is *3*.<br>2) *arr = [2,3]*, where the median is *(2 + 3) / 2 = 2.5*.<br><br>Implement the MedianFinder class:<br>1) *MedianFinder()* initializes the *MedianFinder* object.<br>2) *void addNum(int num)* adds the integer *num* from the data stream to the data structure.<br>3) *double findMedian()* returns the median of all elements so far. Answers within *10^-5* of the actual answer will be accepted.	O(log(n))	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(log (n))**<br>Memory Complexity: **O(n)**	Min-Heap + Max-Heap	Single Vector	Linked List	Two Arrays	A	**Correct!**<br><br>We use a max-heap and min-heap to keep track of the elements in the data stream. The max-heap stores the smaller half of the elements and the min-heap the larger half.<br><br>The size of the max-heap should be either equal to or one more than the size of the min-heap, depending on the total number of elements.<br><br>When a new element is added to the stream, it is first inserted into either the max-heap or the min-heap depending on its value. The heaps are then balanced by moving elements from one heap to the other, as needed.<br><br>To find the median, we check the size of the heaps. If the size of the max-heap is greater than the size of the min-heap, we return the top element of the max-heap as the median. Otherwise, we return the average of the top elements of both heaps as the median.<br><br>Time Complexity: **O(log(n))**<br>Memory Complexity: O(1)	**Suboptimal!**<br><br>Sorting the entire array every time *findMedian()* is called will take O(n log(n)) time, making it inefficient for large input sizes.	Not the best approach.<br><br>Here, the idea is to use a linked list to store the elements and traverse through it every time findMedian() is called.<br><br>This approach is suboptimal because it will take O(n) time to traverse through the linked list every time findMedian() is called, which can become inefficient for large input sizes.	Weaker than using the min-heap and max-heap.<br><br>Here, the idea is to maintain two arrays, one for elements smaller than the current median and the other for elements larger than the current median.<br><br>This approach is suboptimal because it will take O(n) time to update both the arrays every time addNum() is called, and it will also take O(n) time to calculate the median every time findMedian() is called.	One naive approach would be to add the incoming integer to an array and sort it every time the median is needed.<br><br>Once the array is sorted, the median can be calculated accordingly by taking the middle element if the size of the array is odd or the average of the middle two elements if the size is even. However, this approach is not optimal as sorting an array takes O(n log(n)) time complexity which is too slow for large inputs.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Find%20Median%20from%20Data%20Stream.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Find%20Median%20from%20Data%20Stream.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Find%20Median%20from%20Data%20Stream.java	https://youtu.be/MJixm2sYABg
Coding Interviews	Priority Queue	Max Value of Equation	https://leetcode.com/problems/max-value-of-equation/	You are given an array *points* containing the coordinates of points on a 2D plane, sorted by the x-values, where *points[i] = [xi, yi]* such that *xi < xj* for all *1 <= i < j <= points.length*. You are also given an integer *k*.<br><br>Return the **maximum value of the equation** *yi + yj + |xi - xj|*, where *|xi - xj| <= k* and *1 <= i < j <= points.length*.<br><br>It is guaranteed that there exists at least one pair of points that satisfy the constraint *|xi - xj| <= k*.	O(n log(n))	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n log(n))**<br>Memory Complexity: **O(n)**	Brute Force With A Twist	Binary Search	Sliding Window + Set	Sliding Window Approach + Single Pointer	C	The twist? Well, you'll have **horrible efficiency!**<br><br>The approach would be to compare all possible pairs of points and calculate the value of the equation for each pair, and return the maximum value found.<br><br>This has a time complexity of O(n^2), which makes it inefficient for large inputs.	**Incorrect!**<br><br>This approach may miss some pairs of points that satisfy the constraint, leading to an incorrect output. It also has a time complexity of O(n*log(n)), which is slower than the optimal approach presented.<br><br>For each point, search for the point with the largest *yi + xj - xi - yj* that satisfies *|xi - xj| <= k*. Return the maximum value found.	**Correct!**<br><br>We use a sliding window technique to ensure that the absolute difference between xi and xj is less than or equal to k. We then use a set to store the current yj-yi values in the window, and calculate the current maximum value of *yi-yi+|xi-xj|* by adding the current *yi-xi* value to the largest *yj+yi* value in the set.<br><br>Time Complexity: **O(n log(n))**, where n is the number of points in the input array.  A set/priority queue also has O(log(n)) insertion and deletion times.<br>Space Complexity: O(n), where n is the number of points in the input array.	**Suboptimal!**<br><br>This approach still has a time complexity of O(n^2) in the worst case scenario, as it may still have to check all possible pairs of points.<br><br>How would it be done? First, initialize a pointer to the leftmost point and move it rightward until it is no longer possible to satisfy the constraint *|xi - xj| <= k*. <br><br>While doing so, calculate the equation value for all pairs of points that satisfy the constraint and keep track of the maximum value. Then, move the pointer to the next point and repeat the process until all points have been considered.	Check all pairs of points i and j such that |xi - xj| <= k and i < j, and compute the value of the equation yi + yj + |xi - xj| for each pair - returning the maximum value found.<br><br>Time complexity here would be O(n^2), since we need to consider all pairs of points that satisfy the constraint.<br>The space complexity is O(1), since we are not using any extra data structures to solve the problem.<br><br>However, this approach is not optimal for large input sizes and can lead to a timeout error on LeetCode.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Max%20Value%20of%20Equation.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Max%20Value%20of%20Equation.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Max%20Value%20of%20Equation.java	https://youtu.be/ShjPkqvlQt0
Coding Interviews	Linked List	Middle Of the Linked List	https://leetcode.com/problems/middle-of-the-linked-list/	Given the *head* of a singly linked list, return the **middle node of the linked list**.<br><br>If there are two middle nodes, return the **second middle** node.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Count-based approach	Vector-based Approach	Binary Search	Floyd's Tortoise And Hare	D	**Twice as complicated as it needs to be!**<br><br>We'd traverse the linked list once to determine its length, then traverse it again to find the middle node by moving len/2 nodes from the head.<br><br>However, this approach requires two traversals of the linked list, which makes it inefficient.	**Inefficient compared to other methods.**<br><br>First, create a vector and add each node of the linked list to it.<br>Then, return the node at index size()/2.<br>This approach uses extra memory to store the nodes of the linked list in a vector, which is unnecessary and inefficient.	**Not a very good idea!**	**Correct!**<br><br>In this algorithm, we use two pointers, a slow *tortoise* pointer and a fast *hare* pointer. The *tortoise* moves one step at a time, while the *hare* moves two steps at a time.<br>By the time the *hare* reaches the end of the linked list, the *tortoise* will be at the middle of the linked list.<br><br>Time Complexity: O(n), where n is the length of the linked list, since we need to traverse the list once.<br>Space Complexity: O(1), since we are only using two pointers.	Simply traverse the entire list to count the number of nodes.  After that, traverse the list again to find the middle node based on the number of nodes counted.<br>For example, we can first traverse the list to count the number of nodes n. Then, we can traverse the list again, this time stopping at the (n/2)+1-th node, which will be the middle node for an odd-number *n*. For even-numbered *n*, we can stop at the **n/2**-th node, which will be the second middle node.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Middle%20of%20the%20Linked%20List.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Middle%20of%20the%20Linked%20List.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Middle%20of%20the%20Linked%20List.java	https://youtu.be/e0O43pGnCVc
Coding Interviews	Linked List	Partition List	https://leetcode.com/problems/partition-list/	Given the *head* of a linked list and a value *x*, partition it such that all nodes **less than** *x* come before nodes **greater than or equal to** *x*.<br><br>You should **preserve** the original relative order of the nodes in each of the two partitions.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Two Pointers	Creating Two New Linked Lists	Quick Sort	Convert to Array + Sort	B	**Incorrect!**<br><br>This approach involves iterating over the linked list and using two pointers to keep track of the nodes less than x and the nodes greater than or equal to x.<br><br>Time Complexity: O(n^2), where n is the length of the linked list, since the list may need to be iterated over multiple times in the worst case.	**Correct!**<br><br>One holds all nodes less than x, and the other holds the remaining nodes, before combining them.<br><br>Note that this solution can be optimized further by not using the two new linked lists and instead rearranging the nodes in the original linked list itself.<br><br>Time Complexity: O(n)<br>Memory Complexity: O(1)	**Ouch!**<br><br>The time complexity of this approach is O(n^2) in the worst case, where n is the length of the linked list. Although this approach has an average-case time complexity of O(n*log(n)), the worst-case performance makes it inefficient for large inputs.	**Brute-force**, and **suboptimal!**<br><br>You can convert the linked list into an array, sort the array, and then convert this sorted array back into a linked list.<br><br>The time complexity of this approach is O(n log(n)), where n is the length of the linked list, since sorting the array takes O(n log(n)) time using a standard sorting algorithm such as Quick Sort or Merge Sort.<br><br>However, this approach requires O(n) extra memory to store the array, making it less space-efficient than the original solution.	1) Initialize two dummy nodes for the two partitions, one for nodes less than x and one for nodes greater than or equal to x.<br>2) Traverse the linked list.  If the node's value is less than x, append it to the less than partition list.  Otherwise, append it to the greater than or equal to partition list.<br>3) Concatenate the two partition lists by setting the next pointer of the last node in the less than partition list to the first node in the greater than or equal to partition list.<br>4) Set the next pointer of the last node in the greater than or equal to partition list to null to terminate the list.<br>5) Return the head of the less than partition list.<br><br>Look for an O(1) space approach!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Partition%20List.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Partition%20List.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Partition%20List.java	https://youtu.be/-aJl8OcnWD0
Coding Interviews	Linked List	Remove Nth Node From End of List	https://leetcode.com/problems/remove-nth-node-from-end-of-list/	Given the *head* of a linked list, remove the *nth* node from the end of the list and return its head.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Two-Pass Algorithm	Vector-based Approach	Hash Table	Count-based approach	A	**Correct!**<br><br>The first pass counts the length of the linked list. The second pass traverses the list to the node to be removed and removes it.<br><br>Time Complexity: O(n), where n is the length of the linked list.<br>Space Complexity: O(1), since the only extra space used is for the dummy node.	**Poor space complexity!**<br><br>We'd traverse the linked list once, and store the nodes in an array or a vector. After that, we remove the nth node from the end by deleting the corresponding node from the array/vector and rebuild the linked list from the remaining nodes.<br><br>Space Complexity: O(n), which may not be feasible if the linked list is very large.	**Poor space complexity.**<br><br>We'd traverse the linked list once, and store the nodes in a map or a hash table with their indices as keys. Then, we'd remove the nth node from the end by deleting the corresponding node from the map/hash table and rebuild the linked list from the remaining nodes.<br><br>This solution has a higher space complexity of O(n) and adds overhead to store the nodes in a map/hash table. Additionally, rebuilding the linked list can be more complex and error-prone.	**Not quite!**<br><br>Traverse the linked list to count the length, and then traverse again to the (length - n)-th node and remove the next node.<br><br>This is similar to the correct solution, but the node to remove is the next node rather than the (length - n + 1)-th node, which will cause issues if n is equal to the length of the list.	1)Traverse the linked list to find its length.<br>2) Calculate the position of the node to remove by subtracting n from the length.<br>3) Traverse the linked list again until reaching the position calculated in step 2.<br>4) Remove the node at the calculated position by adjusting the pointers of its previous and next nodes.<br>5) Return the head of the modified linked list.<br>6) This approach requires two passes through the linked list and has a time complexity of O(n), where n is the length of the linked list.<br><br>However, there are more efficient approaches that require only a single pass through the linked list.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Remove%20Nth%20Node%20From%20End%20of%20List.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Remove%20Nth%20Node%20From%20End%20of%20List.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Remove%20Nth%20Node%20From%20End%20of%20List.java	https://youtu.be/g1xYYAex1rI
Coding Interviews	Linked List	Linked List Cycle	https://leetcode.com/problems/linked-list-cycle/	Given *head*, the head of a linked list, determine if the linked list has a cycle in it.<br><br>There is a cycle in a linked list if there is some node in the list that can be reached again by continuously following the *next* pointer. Internally, *pos* is used to denote the index of the node that tail's *next* pointer is connected to. **Note that** *pos* **is not passed as a parameter**.<br><br>Return *true* **if there is a cycle in the linked list**. Otherwise, return *false*.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Floyd's Tortoise And Hare	Traversal + Visited Array	Reverse The Linked List	Floyd's Hash Table	A	**Correct!**<br><br>This algorithm is widely used because it is simple, efficient, and **easy to implement**!<br><br>We create two pointers, *tortoise* and *hare*, then advance them through the linked list (LL). The *tortoise* pointer moves **one step at a time**, while the *hare* pointer moves **two steps at a time**. If there is a cycle, *hare* will catch up with *tortoise* at some node in the cycle. Otherwise, the *hare* pointer will simply reach the end of the LL.<br>Time Complexity: **O(n)**, where *n* is the length of the LL.<br>Space Complexity: **O(1)**, as we only need to store two pointers regardless of the size of the LL.	**Suboptimal**, but only because this approach requires us to traverse the entire linked list, even if there is no cycle. In the worst case, it takes **O(n)** time, which is the same as the correct answer.<br><br>The approach involves traversing the linked list while keeping track of the number of nodes visited. If the number of visited nodes exceeds the length of the linked list, return *true*, as there must be a cycle.<br>Time complexity: O(n)<br>Space complexity: O(1)	Incorrect - we **shouldn't** modify the structure of the linked list!<br><br>The idea is to reverse the linked list, then traverse it while keeping track of the previous node. If we encounter a node that points to a previous node, return true, as there must be a cycle.<br>If we reverse the linked list and there is no cycle, we will end up with a completely different linked list, and our algorithm will return *false* even if the original list had a cycle.	**No.**<br><br>Floyd was involved with many pioneering concepts in computer science, but a *Floyd hash table* isn't one of them.<br><br>Incidentally, an approach with a hash table is suboptimal because it requires O(n) space - at the same time, inserting and searching in the hash table can take up to *O(n)* time in the worst case if there are **hash collisions**.	Simply use a **set**.  Add the nodes to the set, and if we encounter the same node twice, we'll know we have a cycle!  It's a slightly simple approach!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Linked%20List%20Cycle.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Linked%20List%20Cycle.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Linked%20List%20Cycle.java	https://youtu.be/kqDCvkD1fqw
Coding Interviews	Linked List	Linked List Cycle II	https://leetcode.com/problems/linked-list-cycle-ii/	Given the *head* of a linked list, **return the node where the cycle begins**. If there is no cycle, return *null*.<br><br>There is a cycle in a linked list if there is some node in the list that can be reached again by continuously following the *next* pointer. Internally, *pos* is used to denote the index of the node that tail's *next* pointer is connected to (**0-indexed**). It is *-1* if there is no cycle. **Note that** *pos* **is not passed as a parameter**.<br><br>**Do not modify** the linked list.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Hash Table	Floyd's Tortoise And Hare	Simple Iteration	Sort-Based Approach	B	**Simplistic, and not the best here!**<br><br>Storing visited nodes in a hash table is a nice idea, but a not the most efficient use of space.<br><br>In this approach, if we find a node that already exists in the hash table, that means we have a cycle, and we can find the starting node by iterating over the linked list again from the head until the first node that appears in the hash table is found.<br><br>However, this requires O(n) space to store the hash table.	**Correct!**<br><br>This approach works very well: it only requires a couple of pointers.<br><br>Be careful: this would require a slight modification of **Floyd's Cycle Detection algorithm**!	**Highly inefficient** for larger linked lists.<br><br>This would be O(n^2) in complexity, where n is the length of the linked list.	A rather **bloated** approach.<br><br>We traverse the linked list, and store the node's value in an array. Then, we traverse this array to find the node with the repeating value.<br><br>This is O(n log(n)) in time complexity, and requires extra space too!	1) Traverse the linked list, keeping track of the nodes visited in a set or a hashmap.<br>2) For each node visited, check if it already exists in the set or hashmap. If it does, return that node as the start of the cycle.<br>3) If the traversal completes and no cycle is found, return null.<br><br>This approach has a time and space complexity of O(n) - look for a more efficient approach!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Linked%20List%20Cycle%20II.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Linked%20List%20Cycle%20II.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Linked%20List%20Cycle%20II.java	https://youtu.be/M8l53WdITfE
Coding Interviews	Linked List	Find the Duplicate Number	https://leetcode.com/problems/find-the-duplicate-number/	Given an array of integers *nums* containing *n + 1* integers where each integer is in the range *[1, n]* inclusive.<br><br>There is only one repeated number in *nums*, **return this repeated number**.<br><br>You must solve the problem **without** modifying the array *nums* and using only **constant extra space**.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Count Sort Variant	Binary Search	Floyd's Tortoise And Hare	California Hash Roll	C	**Nope!**<br><br>Although this approach has a time complexity of **O(n)**, it requires extra space to store the counts of each element - which violates the requirement of using **constant extra space!**	**Not optimal!**<br><br>This involves creating a range from 1 to n, and counting the number of elements in nums that are within that range. If the count is greater than the range, then the repeated number must be within that range. Otherwise, it is outside that range.<br><br>This approach has a time complexity of **O(n log(n))**, which is slower than **Floyd's Tortoise and Hare**.  It also needs extra space to store the range, which **violates the requirement of using constant extra space!**	This is also known as the **Cycle Detection Algorithm**, and is **correct!**<br><br>This works by using two pointers (*tortoise* and *hare*), where the *hare* moves twice as fast through the list as the *tortoise*.  If there is a cycle in the linked list, the hare will eventually catch up to the tortoise. Once they meet, we reset the tortoise to the beginning and move both pointers at the same speed until they meet again, which will be the start of the cycle.<br><br>In this case, we can apply the same concept to the array by treating each value as a pointer to the next index to move to. Since there is only one repeated number in the array, the repeated number is part of the cycle, and thus, the algorithm can find it.<br><br>Time Complexity: O(n)<br><br>Memory Complexity: O(1)	No algorithm has this name - if you find a job in the Silicon Valley or Orange County, you might smell someone smoking this Californian delicacy if you keep your windows open.	Use two nested loops.<br>The outer loop would iterate through each element of the array, and the inner loop would check all the subsequent elements of the array to see if any of them match the current element. If a match is found, we have found the duplicate element, and we can return it.<br><br>This approach would have a time complexity of **O(n^2)**, which is not very efficient for large arrays.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Find%20the%20Duplicate%20Number.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Find%20the%20Duplicate%20Number.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Find%20the%20Duplicate%20Number.java	https://youtu.be/2tX6UGGjYc4
Coding Interviews	Linked List	Merge K Sorted Lists	https://leetcode.com/problems/merge-k-sorted-lists/	You are given an array of *k* linked-lists *lists*, each linked-list is sorted in ascending order.<br><br>**Merge all the linked-lists into one sorted linked-list and return it**.	O(n log(k))	O(k)	We're expecting an optimized solution of:<br>Time Complexity: **O(n log(k))**<br>Memory Complexity: **O(k)**<br><br>*n* is the number of nodes, and *k* the number of lists.	Flatten + Sort	Divide And Conquer	Traversal + Compare All Linked Lists	Min-Heap	D	Slower than the optimal solution.<br><br>This approach flattens all linked lists into a vector, which takes O(n) time and O(n) space, where n is the total number of nodes in all k lists.<br><br>Sorting the vector takes O(n log(n)) time, and creating a new linked list takes O(n) time. Therefore, the overall time complexity is O(n log(n)).	An **inefficient** approach when the number of linked lists is large.<br><br>This method repeatedly merges pairs of linked lists. The time complexity is O(nk log(k)), where n is the total number of nodes in all k lists, and k is the number of lists.	**Unwise.**<br><br>This approach traverses all linked lists to find the minimum element in each iteration.<br><br>The time complexity is O(nk^2), where n is the total number of nodes in all k lists, and k is the number of lists.	**Correct!**<br><br>Our method uses a min heap to merge the linked lists. Initially, all the first elements of the linked lists are added to the heap.<br><br>Then, the minimum element is popped from the heap and added to the result list. If the popped element has a next element, it is added to the heap. This process is repeated until the heap is empty.<br><br>Time Complexity: **O(n log(k))**, where n is the total number of nodes in all k lists, and k is the number of lists. The log(k) factor comes from the time taken to heapify the min heap, which has a maximum size of k.<br>Space Complexity: **O(k)**, as the min heap contains at most k elements.	1) Initialize an empty list to store all the values from the linked lists.<br>2) Iterate through each linked list in the input array.<br>3) For each linked list, iterate through each node and append the node's value to the list.<br>4) Sort the list of values in ascending order.<br>5) Create a new linked list and add the sorted values as nodes in the correct order.<br>6) Return the head of the new linked list.<br><br>This approach has a time complexity of O(n log(n)), and is easily improved upon!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Merge%20k%20Sorted%20Lists.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Merge%20k%20Sorted%20Lists.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Merge%20k%20Sorted%20Lists.java	https://youtu.be/gdoBr4bJaRc
Coding Interviews	Linked List	Insert Into a Sorted Circular Linked List	https://leetcode.com/problems/insert-into-a-sorted-circular-linked-list/	Given a Circular Linked List node, which is sorted in non-descending order, write a function to insert a value *insertVal* into the list such that it remains a sorted circular list. The given node can be a reference to any single node in the list and may not necessarily be the smallest value in the circular list.<br><br>If there are multiple suitable places for insertion, you may choose any place to insert the new value. After the insertion, the circular list should remain sorted.<br><br>If the list is empty (i.e., the given node is *null*), you should create a new single circular list and return the reference to that single node. Otherwise, you should return the originally given node.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	Insertion Sort Variant	Simple Traversal	Traversal + Store Min/Max Values	Create + Append A New Node	A	**Correct!**<br><br>Our algorithm iterates through the circular linked list and checks the current node and the next node to determine the insertion position of the new node.<br>It then checks if the new node value lies between the current node value and the next node value. If not, it continues iterating until it finds a suitable position.<br>If the list is empty, it creates a new single circular list and returns a reference to that single node.<br><br>Time Complexity: O(n), where n is the number of nodes in the circular linked list.<br>Space Complexity: O(1), since only a constant amount of extra space is required to store temporary variables.	**Not quite right.**<br><br>The idea is to start from the head and traverse the linked list until we find the correct position to insert the new node. If we reach the head again without finding the position, insert the new node before the head.<br><br>However, this approach doesn't work because it only considers the head node and doesn't take into account the possibility that the insertion position may be between two nodes other than the head.	**Suboptimal.**<br><br>This requires an additional traversal of the linked list to find the minimum and maximum values, which is unnecessary.<br><br>Also, it doesn't take into account the fact that the linked list is sorted, so the insertion position can be found by comparing values as we traverse the list.	**Incorrect.**<br><br>This approach doesn't preserve the original circular structure of the linked list. Also, it requires an additional traversal of the linked list to find the minimum node, which is unnecessary.	Traverse the circular linked list to find the suitable insertion point for the new value. This point lies between two nodes, where the new value is greater than the previous node's value and less than or equal to the next node's value.<br><br>If the new value is beyond the linked list's minimum or maximum value, insert it at the start or end respectively.<br><br>For an empty circular linked list, create a new node with insertVal as its value, and have it point to itself.<br><br>Upon identifying the insertion point, create a new node with insertVal and adjust pointers to insert it between the two nodes.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Insert%20into%20a%20Sorted%20Circular%20Linked%20List.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Insert%20into%20a%20Sorted%20Circular%20Linked%20List.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Insert%20into%20a%20Sorted%20Circular%20Linked%20List.java	https://youtu.be/5DEBsSfKZgU
Coding Interviews	Linked List	Copy List with Random Pointer	https://leetcode.com/problems/copy-list-with-random-pointer/	Given a linked list of length *n* with nodes having an additional *random* pointer that can point to any node in the list or *null*, **construct a deep copy of the list**.<br><br>The **deep copy** should consist of *n* **brand new** nodes, each with its value set to the value of its corresponding original node. Both the *next* and *random* pointers of the new nodes should point to new nodes in the copied list, representing the same list state as the original. **None of the pointers in the new list should point to nodes in the original list.**<br><br>Return the *head of the copied linked list*. Each *node* is represented as *[val, random_index]*, where *val* is an integer representing *Node.val*, and *random_index* is the index of the node (ranging from *0* to *n-1*) that the *random* pointer points to, or *null* if it does not point to any node.<br><br>(Note: Your code will **only** receive the *head* of the original linked list as input.)	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Recursive Approach	Linear Iteration + Hash Table	Recursion + Hashing	Triple Pass of the Linked List	B	This could potentially cause a stack overflow error for large linked lists.<br><br>Using a recursive function to create the new linked list by traversing the original one and copying each node and its random pointer recursively.<br><br>This approach has a time complexity of O(n^2).	**Correct!**<br><br>We iterate through the linked list and create a new node for each node in the original list, copying its value and random pointer.  The key (no pun intended) here is to also store a mapping between the original nodes and their corresponding new nodes in an hash table.<br><br>After creating the new nodes, you iterate through the list again and update the random pointers of each new node to point to the corresponding new node that the original random pointer points to, using the mapping in the hash table.<br><br>Time Complexity: O(n), where n is the length of the linked list.<br>Space Complexity: O(n)	Stack overflow is a possibility, and not in a good way!<br><br>In this approach, you use a recursive function to create a deep copy of the linked list, and store the mapping between the original and new nodes in an hash table. The recursive function takes a node as input and returns the corresponding new node.<br><br>If a node has already been created, the function retrieves it from the hash table, otherwise it creates a new node and stores it in the hash table. This approach has a time complexity of O(n), but it uses recursion and may lead to **stack overflow** for very long linked lists.	**Ouch!**<br><br>This approach has a time complexity of O(n^2), which is very inefficient as the list gets larger.	The brute-force approach might be quite close to a good solution here, so we're withholding given one on this occasion.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Copy%20List%20with%20Random%20Pointer.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Copy%20List%20with%20Random%20Pointer.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Copy%20List%20with%20Random%20Pointer.java	https://youtu.be/JUfgWw-zXTk
Coding Interviews	Binary Tree	Binary Tree Right Side View	https://leetcode.com/problems/binary-tree-right-side-view/	Given the *root* of a binary tree, imagine yourself standing on the **right side** of it, return the *values of the nodes* you can see *ordered from top to bottom*.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Inorder Traversal + Right-most Node Stored	Inorder Traversal + Left-most Node Stored	BFS (Breadth-First Search) + Level Traversal	Recursive Traversal + Hash Table	C	Incorrect!<br><br>The right-most node at each level may not necessarily be visible from the right side of the tree.	An all-round **incorrect approach** to solving the problem.  Try a different idea!	**Correct!**<br><br>Method:<br>1) We traverse the binary tree **level-by-level**, keeping track of the rightmost node at each level.<br>2) At the end of each level, we add the **rightmost node** to our result vector.<br>3) In our approach, we use a queue to both process the nodes, and keep track of the nodes to be processed.<br><br>Time Complexity: **O(n)**, since each node is visited at least once.<br>Space Complexity: **O(n)** -  in the worst case, we would store all nodes in the queue simultaneously.	**Not quite!**<br><br>This is slower than the queue-based BFS approach due to the overhead of map operations.<br><br>Method: recursively add the nodes at each depth to a map of <depth, value>, then return the values from the map for the maximum depth.<br>Key weakness: this approach is suboptimal because it uses **extra space** to store the map.	Perform a **level-order traversal** of the binary tree. For each level, add the value of the rightmost node to the result list, then return the result **list**.<br><br>This approach works because during level-order traversal, the nodes at each level are processed from left to right. Therefore, the rightmost node at each level is the last one to be processed, and hence it is the node that is visible from the right side of the tree.<br><br>This approach is nearly identical to the correct answer to this problem, so **remove one mark from your final score** ;)	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Binary%20Tree%20Right%20Side%20View.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Binary%20Tree%20Right%20Side%20View.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Binary%20Tree%20Right%20Side%20View.java	https://youtu.be/SRfeKWMyjbk
Coding Interviews	Binary Tree	Convert Binary Search Tree to Sorted Doubly Linked List	https://leetcode.com/problems/convert-binary-search-tree-to-sorted-doubly-linked-list/description/	Convert a **Binary Search Tree** to a sorted **Circular Doubly-Linked List** **in place**.<br><br>You can think of the left and right pointers as synonymous to the predecessor and successor pointers in a doubly-linked list. For a circular doubly linked list, the predecessor of the first element is the last element, and the successor of the last element is the first element.<br><br>We want to do the transformation **in place**. After the transformation, the left pointer of the tree node should point to its predecessor, and the right pointer should point to its successor. You should return the pointer to the smallest element of the linked list.	O(n)	O(h)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(h)**	Inorder Traversal + Sorting	Breadth-First traversal + Queue	Recursive Inorder Traversal + Doubly Linked List	Recursive Depth-First Search + Doubly Linked List	D	The idea is to use a queue to keep track of the current level of nodes. We traverse the tree and update the pointers to create the DLL!<br><br>This approach has a time complexity of **O(n log(n))** due to sorting and a memory complexity of **O(n)** for storing the node values.	Due to the use of the queue, this approach would have a memory complexity of O(n), which **isn't quite optimal** here.	Highly inefficient.<br><br>The idea?  Perform recursive inorder traversal of the tree, creating the DLL as we go.  For each node, traverse its left subtree, append the node to the end of the linked list, and then traverse its right subtree.<br><br>This approach has a time complexity of **O(n^2)** for traversing the linked list each time a node is appended, with a memory complexity of **O(1)**.  However, **O(1)** memory complexity is achieved much more efficiently using **Morris traversal** (which was not listed among this set of answers)!	Correct...for this set of answers!<br><br>Here, the **recursion stack** has a maximum depth of the **height of the tree**, which is **O(h)** in memory.<br><br>We combine the left and right subtrees with the current node in the middle, forming the final DLL.<br><br>One could use a stack or queue to simulate the recursive call stack, but this would not improve the space or time complexity!<br><br>**Morris traversal** (not LISTED here!) is even better in terms of space complexity, but it is a little obscure for most people!	Perform an in-order traversal of the BST to get the nodes in sorted order, then create a circular DLL from the sorted nodes, like so:<br>1) Traverse the left subtree recursively and then visit the current node.<br>2) Store the previous node visited during the traversal in a variable.<br>3) Set the left pointer of the current node to the previous node.<br>4) If the previous node is not null, set its right pointer to the current node.<br>5) Set the current node as the previous node for the next iteration.<br>6) Traverse the right subtree recursively.<br>7) Once the traversal is complete, set the left pointer of the first node to the last node, and the right pointer of the last node to the first node to make it a circular DLL.<br>This approach has a time complexity of O(n) since it visits each node in the binary search tree exactly once, and a space complexity of O(n) for the recursive call stack.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Convert%20Binary%20Search%20Tree%20to%20Sorted%20Doubly%20Linked%20List.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Convert%20Binary%20Search%20Tree%20to%20Sorted%20Doubly%20Linked%20List.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Convert%20Binary%20Search%20Tree%20to%20Sorted%20Doubly%20Linked%20List.java	https://youtu.be/IlB34AFpZVc
Coding Interviews	Binary Tree	Diameter of Binary Tree	https://leetcode.com/problems/diameter-of-binary-tree/	Given the *root* of a binary tree, return the *length of the* **diameter** *of the tree*.<br><br>The **diameter** of a binary tree is the **length** of the longest path between any two nodes in a tree. This path may or may not pass through the *root*.<br><br>The **length** of a path between two nodes is represented by the number of edges between them.	O(n)	O(h)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(h)**	In-order Traversal Of All Nodes	Recursive Approach	Two Pair	Traversal + Hash Set	B	**Inefficient!**<br><br>Method: traverse all nodes and find the longest path between any two nodes.<br><br>Weakness: this approach is suboptimal because it has a time complexity of O(n^2) - wildly inefficient, especially for larger trees.	**Correct!**<br><br>Method:<br>1) Recursive calculation of the height of the binary tree, with the base case being when the root is null (returning 0).<br>2) The height of a node is the maximum of the height of its left and right subtrees plus one (for the root itself).<br>3) During the height calculation, the maximum diameter is updated by taking the sum of left and right heights of the current node, then checking if it is greater than the current maximum diameter.<br><br>Time Complexity: O(n) because each node is visited once<br>Memory Complexity: O(h), where h is the height of the tree, due to the recursive calls.	**No!**<br><br>**Two pair** is frequently a winning hand in poker, but isn't used in computer science yet.	**Suboptimal.**<br><br>This would require storing the maximum diameter of each node, which would be more efficiently done during the height calculation itself.<br><br>The main weakness? This requires much more memory than the optimal approach.	In our opinion, the dominant brute-force option we chose was very close to the solution.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Diameter%20of%20Binary%20Tree.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Diameter%20of%20Binary%20Tree.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Diameter%20of%20Binary%20Tree.java	https://youtu.be/uGH_xgZRuYQ
Coding Interviews	Binary Tree	Subtree of Another Tree	https://leetcode.com/problems/subtree-of-another-tree/	Given the roots of two binary trees *root* and *subRoot*, return *true* if there is a subtree of *root* with the same structure and node values of *subRoot* and *false* otherwise.<br><br>A subtree of a binary tree *tree* is a tree that consists of a node in *tree* and all of this node's descendants. The tree *tree* could also be considered as a subtree of itself.	O(mn)	O(m+n)	We're expecting an optimized solution of:<br>Time Complexity: **O(mn)**<br>Memory Complexity: **O(m+n)**	Tree Serialization + Pattern Matching	Convert Into Preorder Strings + Compare	Pre-Order Traversal + Comparison	Depth-First Search	A	**Correct!**<br><br>Alternative approaches may include traversing both trees in a recursive manner to compare node values and subtrees, which can have a better time complexity depending on the specific implementation.<br><br>The time complexity of this approach is **O(mn)**, where m and n are the number of nodes in root and subRoot, respectively, since we need to serialize both trees and then search for the subRoot string in the root string.<br><br>The space complexity is **O(m+n)**, since we need to store the serialized strings of both trees.	This approach is **suboptimal** because it does not consider the tree structure and only relies on the node values.	**Suboptimal** because it may miss cases where the subRoot is a subtree of root but not a contiguous part of the tree.<br><br>This approach traverses both trees simultaneously in pre-order and compare each node of subRoot to the corresponding node of root.	This approach is **suboptimal** because it checks each possible subtree, even if it is clear that the current node cannot be the root of the subRoot tree.<br><br>The idea is to use DFS to traverse the tree and check if each subtree rooted at the current node is equal to subRoot - but there are better approaches!	1) Define a recursive function isIdentical(node1, node2) that returns true if the two trees rooted at node1 and node2 are identical, and false otherwise.<br>2) The base case for the recursion is when either node1 or node2 is null. In this case, return true if both node1 and node2 are null, and false otherwise.<br>3) If the values of node1 and node2 are different, return false.<br>4) Recursively call isIdentical on the left and right subtrees of node1 and node2, and return true if both calls return true.<br>5) Traverse the root tree recursively. For each node encountered, call isIdentical with its subtree and the subRoot tree. If the call returns true, return true.<br>6) If no subtree of root is identical to the subRoot tree, return false.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Subtree%20of%20Another%20Tree.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Subtree%20of%20Another%20Tree.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Subtree%20of%20Another%20Tree.java	https://youtu.be/ytRWnuu8SZU
Coding Interviews	Binary Tree	Flip Equivalent Binary Trees	https://leetcode.com/problems/flip-equivalent-binary-trees/	For a binary tree **T**, we can define a **flip operation** as follows:<br>1) Choose any node<br>2) Swap the left and right child subtrees<br><br>A binary tree **X** is *flip equivalent* to a binary tree **Y** if and only if we can make **X** equal to **Y** after some number of flip operations.<br><br>Given the roots of two binary trees *root1* and *root2*, return *true* if the two trees are flip equivalent or *false* otherwise.	O(n)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(n)**	Inorder and Postorder Traversal + Comparison	HSO Algorithm	Canonical Parenthesis Representation	Parallel Traversal + Comparison	C	**Incorrect!**<br><br>Two trees can have different shapes but still be flip equivalent!	**D'oh!**<br><br>This stands for the **Homer Simpson Optimization Algorithm**, which looks for the laziest and most inefficient solution to the problem.<br><br>Perfect for those who look at a problem and think **Can't someone else do it?**	**Correct!**<br><br>The method constructs a string representation of the binary tree for each input tree by performing a **canonical parenthetical traversal**. This traversal ensures that subtrees with the same structure are represented in the same way.<br><br>The method then compares the two string representations for equality to determine if the two trees are flip equivalent.<br><br>Time Complexity: O(n), where n is the number of nodes in the larger tree, as each node is visited once during the traversal.<br>Memory Complexity: O(n) for storing the string representation of the tree.	**Inferior** because it is more complex than the solution provided, which simply compares the canonical representations of the trees. Additionally, this approach may not terminate if the trees are not flip equivalent.	Check if the roots of the two given trees are either equal or symmetric. If they are, then we recursively check if their left and right subtrees are flip equivalent. If both subtrees are flip equivalent, then we return true, otherwise we return false.<br><br>This approach has a time complexity of O(n^2) in the worst case, where n is the number of nodes in the tree.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Flip%20Equivalent%20Binary%20Trees.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Flip%20Equivalent%20Binary%20Trees.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Flip%20Equivalent%20Binary%20Trees.java	https://youtu.be/ot-vNFX0R3o
Coding Interviews	Binary Tree	Lowest Common Ancestor of a Binary Tree	https://leetcode.com/problems/lowest-common-ancestor-of-a-binary-tree/	Given a binary tree, find the lowest common ancestor (LCA) of two given nodes in the tree.    According to the definition of **LCA** on Wikipedia:<br>*The lowest common ancestor is defined between two nodes* **p** and **q** *as the lowest node in* **T** *that has both* **p** *and* **q** *as descendants (where we allow a node to be a descendant of itself)*.	O(n)	O(h)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(h)**	Traversal + Two Arrays	Recursive Approach	Node-by-node calculation	Convert into BST	B	**Inferior!**<br><br>This approach has a time complexity of O(n^2) in the worst case (when the two nodes are the farthest apart in the tree) and requires O(n) extra space to store the two arrays.	**Correct!**<br><br>It checks if the root is *null* or if the root is either *p* or *q*, and if so, it returns the root. Then it recursively checks for the lowest common ancestor in the left and right subtrees of the root. The final result is the root itself if both left and right subtrees have non-null values, left subtree if left is non-null, and right subtree if right is non-null.<br><br>Time Complexity: **O(n)**, where n is the number of nodes in the binary tree.<br>Space Complexity: **O(h)**	**Rather inefficient.**<br><br>For each node in the tree, calculate the distance from the node to both p and q, and keep track of the node with the smallest sum of distances.<br><br>This approach has a time complexity of O(n^2) in the worst case (when the two nodes are the farthest apart in the tree), as for each node in the tree we need to traverse to p and q, and a space complexity of O(1) as we are not storing any additional data structures.	**Incorrect!**<br><br>This can modify the structure of the original binary tree, which would result in an incorrect lowest common ancestor. Additionally, it's not always possible to convert a binary tree to a binary search tree without changing the structure of the tree.	Perform a post-order traversal of the tree.  <br>For each node encountered during the traversal, check if the node is either p or q. If the node is either p or q, return the node. If the node is not p or q, check if both p and q are descendants of the node. If so, return the node. If not, continue traversing the tree until a node is found that satisfies one of the previous conditions. If no such node is found, return null.<br><br>Time Complexity: O(n^2)<br>Space Complexity: O(h), where h is the height of the tree, due to the use of a call stack during the traversal.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Lowest%20Common%20Ancestor%20of%20a%20Binary%20Tree.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Lowest%20Common%20Ancestor%20of%20a%20Binary%20Tree.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Lowest%20Common%20Ancestor%20of%20a%20Binary%20Tree.java	https://youtu.be/izqAtp8ACsE
Coding Interviews	Binary Tree	Lowest Common Ancestor of a Binary Tree III	https://leetcode.com/problems/lowest-common-ancestor-of-a-binary-tree-iii/	Given two nodes of a binary tree *p* and *q*, return their lowest common ancestor (LCA).<br><br>Each node will have a reference to its parent node.<br><br>The definition for *Node* is a class called *Node* containing *public int val*, *public Node left*, *public Node right*, and *public Node parent*.<br><br>According to the definition of **LCA** on Wikipedia:<br>*The lowest common ancestor is defined between two nodes* **p** and **q** *as the lowest node in* **T** *that has both* **p** *and* **q** *as descendants (where we allow a node to be a descendant of itself)*.	O(h)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(h)**<br>Memory Complexity: **O(1)**	Traversal + Set	Level-order Traversal	Recursive Traversal	Traversal Of Parent Pointers	D	**Poor space complexity!**<br><br>This approach requires additional memory to store the visited nodes, and may have a worst-case time complexity of O(n) when the binary tree is degenerate, resulting in a long parent chain for one of the nodes.<br><br>It's done by starting from one of the nodes, traversing up the parent node chain until reaching the root node, and storing all visited nodes in a set.<br><br>Then, starting from the other node, traverse up the parent node chain, checking if any of the visited nodes have already been encountered. Return the first encountered node.	**Not ideal.**<br><br>Perform a level-order traversal on the binary tree, and check each level to see if both nodes are present. When the nodes are not present on the same level, return the previously seen level's common ancestor.<br><br>This approach is inefficient, as it requires checking all nodes in the binary tree, and it may also require additional storage to keep track of the previously seen level's common ancestor.	**Quite inefficient!**<br><br>Starting from the root node, recursively traverse the binary tree while maintaining a path for both nodes. Return the deepest common node in the path.<br><br>This approach has a time complexity of O(n^2) in the worst case scenario where the binary tree is unbalanced, and the two nodes are on opposite sides of the tree.	**Correct!**<br><br>Starting from the given nodes, we traverse their respective parent pointers until we reach a common node, which is the lowest common ancestor (LCA) of the two nodes.<br><br>Time Complexity: **O(h)** where h is the height of the tree.<br>Space complexity: **O(1)**	1) Start from node p and traverse up to its root by following its parent pointers, and store all the nodes visited in a hash set.<br>2) Start from node q and traverse up to its root by following its parent pointers. At each step, check if the current node is present in the hash set of nodes visited in step 1. If it is, then this is the lowest common ancestor.<br>3) If the root is reached in step 2 without finding the lowest common ancestor, repeat the same process by starting from node q and traversing up to its root, and storing the visited nodes in a hash set. Then, start from node p and traverse up to its root, checking at each step if the current node is present in the hash set of nodes visited in step 2.<br><br>The space complexity is very **poor** here, with **O(1)** possible with other approaches.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Lowest%20Common%20Ancestor%20of%20a%20Binary%20Tree%20III.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Lowest%20Common%20Ancestor%20of%20a%20Binary%20Tree%20III.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Lowest%20Common%20Ancestor%20of%20a%20Binary%20Tree%20III.java	https://youtu.be/ydG6tEvQrw4
Coding Interviews	Binary Tree	Intersection of Two Linked Lists	https://leetcode.com/problems/intersection-of-two-linked-lists/	Given the heads of two singly linked-lists *headA* and *headB*, **return the node at which the two lists intersect**. If the two linked lists have no intersection at all, return *null*.<br><br>The test cases are generated such that there are no cycles anywhere in the entire linked structure. Note that the linked lists must **retain their original structure** after the function returns.<br><br>See the LeetCode link for a more detailed problem statement.	O(n+m)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(m+n)**<br>Memory Complexity: **O(1)**<br><br>N.B. there are multiple alternatives too!	Traversal + Two Arrays	Traversal + Direct Comparison	Traversal + Hash Set	Two Pointers	D	**No!** The solution can be achieved in O(1) space.<br><br>In this approach, we create two pointers, one for each linked list, and iterate over them until they meet. To ensure that both pointers have traveled the same distance when they collide, we reset a pointer to the head of the opposite list when it reaches the end of its own list.<br><br>This allows us to find the intersection point of the two linked lists in O(m + n) time, where m and n are the lengths of the linked lists. This approach requires O(n) space complexity and is suboptimal compared to the O(1) space complexity required by the correct solution.	This approach has a time complexity of O(n^2), which is obviously inefficient for large linked lists.	**Unfortunately, no!**<br><br>This approach requires O(n) space complexity and is suboptimal compared to the O(1) space complexity required by the correct solution. Additionally, it also requires two passes through the linked lists, whereas the correct solution only requires one pass.<br><br>The idea is that we traverse linked list A and store all the node addresses in a hash set. Then, traverse linked list B and for each node, check if it exists in the hash set.	**Correct!**<br><br>In this approach, we create two pointers, one for each linked list, and iterate over them until they meet. To ensure that both pointers have traveled the same distance when they collide, we reset a pointer to the head of the opposite list when it reaches the end of its own list.<br><br>This allows us to find the intersection point of the two linked lists in O(m+n) time, where m and n are the lengths of the linked lists.	Traverse through both linked lists, comparing each node of the first list with every node of the second list until a matching node is found.  Look for a more efficient approach!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Intersection%20of%20Two%20Linked%20Lists.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Intersection%20of%20Two%20Linked%20Lists.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Intersection%20of%20Two%20Linked%20Lists.java	https://youtu.be/MSrt38XyS0c
Coding Interviews	Binary Tree	Lowest Common Ancestor of a Binary Search Tree	https://leetcode.com/problems/lowest-common-ancestor-of-a-binary-search-tree/	Given a binary search tree (BST), **find the lowest common ancestor (LCA) node of two given nodes in the BST**.<br><br>According to the definition of **LCA** on Wikipedia:<br>*The lowest common ancestor is defined between two nodes* **p** and **q** *as the lowest node in* **T** *that has both* **p** *and* **q** *as descendants (where we allow a node to be a descendant of itself)*.	O(h)	O(h)	We're expecting an optimized solution of:<br>Time Complexity: **O(h)**<br>Memory Complexity: **O(h)**	Simple Parent Pointer Usage	Inorder Traversal While Storing Path	Iterative Approach	Recursive Approach	D	**Suboptimal.**<br><br>This approach involves storing parent pointers for each node in the tree, traversing from p and q to their respective root nodes, and then finding the first common node between the two paths.<br><br>This has a time complexity of O(h).<br>However, this approach requires additional space to store the parent pointers, making it less memory-efficient.	**Not ideal.**<br><br>This approach involves storing the paths from root to p and root to q, then finding the last common node in the paths.<br><br>It's suboptimal because it has a time complexity of O(n) and a space complexity of O(n), making it less efficient than the recursive approach.	**Overly complex**<br><br>This iterates through the tree and checks each node to find the LCA. This approach has a higher time complexity than the recursive approach and is also more complex to implement.<br><br>Suboptimal because the time complexity can be as high as O(n) in the worst case scenario where the tree is skewed, making the algorithm inefficient.	**Correct!**<br><br>Our method traverses the tree recursively to find the LCA of the given two nodes in the BST.<br><br>The algorithm starts at the root of the tree and checks if the root is either p or q or null. If any of these conditions are true, the root is returned.<br><br>We then search for p and q in the left and right subtrees of the root. If both p and q are found in the left and right subtrees, then the current root is the LCA. If only p or q is found, the search continues in that subtree.<br><br>Time Complexity: O(h), where h is the height of the tree.<br>Space Complexity: O(h) due to the recursion stack.	Traverse the tree from the root node to each of the given nodes to find their paths, then compare the paths to find the lowest common ancestor. Here are the steps:<br>1) Traverse the tree from the root node to the first given node, storing the path in an array or a stack.<br>2) Traverse the tree from the root node to the second given node, storing the path in another array or stack.<br>3) While the two paths have the same node at the top, pop the top node from both paths.<br>4) The last common node is the lowest common ancestor.<br><br>This approach has a time complexity of O(n), where n is the number of nodes in the tree.  Find an alternative in O(h)!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Lowest%20Common%20Ancestor%20of%20a%20Binary%20Search%20Tree.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Lowest%20Common%20Ancestor%20of%20a%20Binary%20Search%20Tree.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Lowest%20Common%20Ancestor%20of%20a%20Binary%20Search%20Tree.java	https://youtu.be/RwFAQZNmHz8
Coding Interviews	Binary Tree	Binary Search Tree Iterator	https://leetcode.com/problems/binary-search-tree-iterator/	Implement the *BSTIterator* class for iterating over the **in-order traversal** of a binary search tree (BST):<br>1) *BSTIterator(TreeNode root)* initializes the iterator with the *root* of the BST. The pointer is initially set to a non-existent number smaller than any element in the BST.<br>2) *boolean hasNext()* returns *true* if there is a number to the right of the pointer, otherwise returns *false*.<br>3) *int next()* moves the pointer to the right and returns the number at the pointer.<br><br>The first call to *next()* returns the smallest element in the BST since the pointer starts at a non-existent smallest number.<br><br>Assume that *next()* calls will always be valid, and there will be at least one more number in the in-order traversal when *next()* is called.	O(1)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(1)**<br>Memory Complexity: **O(n)**	Depth-first Traversal	Breadth-first Traversal	Inorder Traversal + Stack	Pre-order Traversal + Stack	C	**No**, as other approaches allow us to do this in O(1) time.<br><br>Depth-first traversal of a Binary Search Tree has **O(n)** time complexity and **O(h)** space complexity using recursion or a stack.	**Not optimal!**  An **inorder traversal and stack** allows us to do this in O(1) time.<br><br>Breadth-first traversal of a Binary Search Tree, using a queue to visit the nodes level-by-level, has O(n) time complexity and O(n) space complexity.	**Correct!**<br><br>Our algorithm initializes the iterator with the root of the BST and pushes all the nodes of the left chain of the root onto the stack.<br>The next() function pops the top node from the stack, and if its right child is not null, pushes all the nodes of its left chain onto the stack. It then returns the value of the popped node.<br>The hasNext() function checks whether the stack is empty or not.<br><br>Time Complexity: **O(1)** for both the *next()* and *hasNext()* operations in the average case.<br>Space Complexity: it looks **O(h)**, where h is the height of the BST.  However, if the tree is completely unbalanced, this can reach **O(n)**, where n is the number of nodes in the BST.	Slightly **confused** approach.<br><br>This iterates over a Binary Search Tree in O(1) time complexity and O(h) space complexity using a stack, but does **not follow the order of the BST**.<br><br>Although it works for traversing the entire tree, it does not provide the values in sorted order as required by the problem.	Perform an in-order traversal of the given binary search tree (BST) and store the elements in a list. The hasNext() method would then simply check if there are any remaining elements in the list, and the next() method would return the next element in the list and move the pointer to the right.<br><br>However, this approach would not satisfy the requirement of O(h) memory, where h is the height of the BST.  What would do so?	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Binary%20Search%20Tree%20Iterator.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Binary%20Search%20Tree%20Iterator.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Binary%20Search%20Tree%20Iterator.java	https://youtu.be/mBtvMBWPDBo
Coding Interviews	Binary Tree	Recover Binary Search Tree	https://leetcode.com/problems/recover-binary-search-tree/	You are given the *root* of a binary search tree (BST), where the values of **exactly** two nodes of the tree were swapped by mistake. **Recover the tree without changing its structure**.	O(n)	O(1)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(1)**	In-order Traversal + Stack	Morris Traversal	Breadth-first Traversal	Depth-first Traversal	B	**Suboptimal!**<br><br>This traverses the tree in O(n) time complexity and O(h) space complexity using a stack to keep track of visited nodes. Although it is a valid approach, it uses extra space and is not optimal when the tree is very large.	**Correct!**<br><br>**Morris Traversal** is a space-efficient method to traverse a binary tree without using a stack or recursion. The algorithm uses threading, which means it modifies the structure of the tree temporarily to reduce the space complexity of the traversal.<br><br>In short, use Morris Traversal to traverse the tree and check if the current node's value is less than the previous node's value.<br><br>Time Complexity: O(n) because you're traversing each node of the tree only once.<br>Space Complexity: O(1) because you're not using any extra space except for three pointers.	**Not quite.**<br><br>Although it works for traversing the entire tree, it does not efficiently identify the two swapped nodes and thus requires further processing. <br><br>Essentially, this approach traverses the tree in O(n) time complexity and O(n) space complexity using a queue to visit the nodes level by level.	Less efficient than other approaches.<br><br>Although a common approach for tree traversal, it does not allow us to identify the two swapped nodes without additional processing.<br><br>Traverses the tree in O(n) time and O(h) space using recursion or a stack.	Perform an in-order traversal of the tree and store the nodes in an array. Since in-order traversal of a BST returns the nodes in non-descending order, any two swapped nodes would appear in the array in an incorrect order. We can then identify the misplaced nodes by comparing each node with its next node in the array, and swap their values to recover the tree.<br><br>However, this requires O(n) space to store the nodes in the array, where n is the number of nodes in the tree - there are better approaches!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Recover%20Binary%20Search%20Tree.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Recover%20Binary%20Search%20Tree.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Recover%20Binary%20Search%20Tree.java	https://youtu.be/RHmQosXGl8U
Coding Interviews	Binary Tree	Binary Tree Maximum Path Sum	https://leetcode.com/problems/binary-tree-maximum-path-sum/	A **path** in a binary tree is a sequence of nodes where each pair of adjacent nodes in the sequence has an edge connecting them. A node can only appear in the sequence **at most once**. Note that the path does not need to pass through the root.<br><br>The **path sum** of a path is the sum of the node's values in the path.<br><br>Given the *root* of a binary tree, return the *maximum* **path sum** *of any* **non-empty** *path*.	O(n)	O(h)	We're expecting an optimized solution of:<br>Time Complexity: **O(n)**<br>Memory Complexity: **O(h)**	DFS + Memoization	Recursive Traversal	BFS	Recursion + Kadane's Algorithm	D	Not quite optimal, although a solid suggestion!<br><br>We can traverse the tree with DFS, and memoize the maximum path sum for each node. While the time complexity is nice at O(n), we need additional space for the memoization - which would be O(n) rather than the optimal O(h).	Overly **naÃ¯ve** - it would mean traversing each node multiple times!<br><br>The time complexity would be O(n^2) in this case.<br><br>Technically, the Kadane's Algorithm for Trees is recursive tooâ€¦but it's really important to invoke Kadane's name if you're intending to use his algorithm!	Not quite optimal!<br><br>BFS can also yield a time complexity of O(n), but needs additional space to store the maximum sum path for each level.	**Correct!**<br><br>Method: we take a recursive approach that traverses the tree, while calculating the maximum sum path passing through each node AND the maximum sum path starting from each node.<br><br>We use **Kadane's algorithm** to calculate the maximum sum path starting from each node, and combine it with the tree diameter problem to calculate the maximum sum path passing through each node.<br><br>Time Complexity: O(n), where n is the number of nodes in the tree.<br>Space Complexity: O(h), where h is the height of the tree, due to the recursion stack.	Traverse every possible path in the binary tree and compute its path sum, keeping track of the maximum path sum seen so far.<br><br>The time complexity of this approach is O(n^2), where n is the number of nodes in the binary tree, because we potentially visit every node in the tree for every other node in the tree. However, we can optimize this approach!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Binary%20Tree%20Maximum%20Path%20Sum.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Binary%20Tree%20Maximum%20Path%20Sum.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Binary%20Tree%20Maximum%20Path%20Sum.java	https://youtu.be/F58zRZupV-Q
Coding Interviews	Hash Tables	Minimum Area Rectangle	https://leetcode.com/problems/minimum-area-rectangle/	You are given an array of points in the **X-Y** plane *points* where *points[i] = [xi, yi]*.<br><br>Return the **minimum area of a rectangle formed from these points, with sides parallel to the X and Y axes. If there is not any such rectangle, return 0**.	O(n^2)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(n^2)**<br>Memory Complexity: **O(n)**<br><br>N.B. our suggested solution is by no means the most efficient for this problem!	Hash Table + Nested Loop	Hash Table + HSO Algorithm	Sorting + Two Pointers	Set	A	**Correct!**<br><br>Method:<br>1) We use a hash table to group the points by their x-coordinates, and then iterate through every pair of distinct points to check if they can form a rectangle.<br>2) This involves using a nested loop over all pairs of points.<br>Time Complexity: **O(n^2)**, where n is the number of points.<br>Space Complexity: **O(n)** for the hash table.	**D'oh!** You've found a joke algorithm!<br><br>The **Homer Simpson Optimization Algorithm** will always look for the **laziest** (yet most **inefficient** solution) to any problem, solving it (and causing another problem) with **alcohol**. This is perfect for those who look at a problem and think **Can't someone else do it?**<br><br>Not so ideal for an interview!	**Inefficient!**<br><br>Method:<br>1) Sort the points first by x-coordinate, and then by y-coordinate.<br>2) For each pair of points (p1, p2) that have the same x-coordinate, check if there exists two other points (p3, p4) with the same y-coordinate. If such points exist, calculate the area of the rectangle formed by (p1, p2, p3, p4) and update the minimum area.<br>Weakness: the time complexity is horrendous, being O(n^2 log(n)) due to sorting and loops.	**Very inefficient!**<br><br>Method:<br>1) Store all the given points in a set of pairs.<br>2) For each pair of points (p1, p2), we check if there exists two other points (p3, p4) such that (p1, p4) and (p2, p3) are diagonals of a rectangle.<br>3) Finally, calculate the area of the rectangle formed by (p1, p2, p3, p4) and update the minimum area.<br>Weakness: this approach has a time complexity of O(n^3), which is very rarely viable for a LeetCode problem!	Iterate through all pairs of points in the array and calculate the distance between them. If these two points share the **same** x-coordinate or y-coordinate, they could be opposite corners of a rectangle - so look for two more points in the array that share the other coordinate with them and form a rectangle.<br><br>Calculate the area of this rectangle and keep track of the minimum area found so far. Then, repeat the steps above for ALL pairs of points in the array, returning the minimum area found.<br><br>The simplest version of this approach has a time complexity of O(n^4), so consider how you can optimize it!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Minimum%20Area%20Rectangle.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Minimum%20Area%20Rectangle.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Minimum%20Area%20Rectangle.java	https://youtu.be/emGappJ3o2w
Coding Interviews	Hash Tables	All O'one Data Structure	https://leetcode.com/problems/all-oone-data-structure/	Design a data structure to store string counts and efficiently retrieve strings with minimum and maximum counts.<br><br>Implement the *AllOne* class:<br>*AllOne()* initializes the data structure.<br>*inc(String key)* Increments the count of the string *key* by *1*. If *key* doesn't exist, insert it with count *1*.<br>*dec(String key)* decrements the count of the string *key* by *1*. If the count becomes *0*, remove *key* from the structure. *key* is guaranteed to exist before the decrement.<br>*getMaxKey()* returns a key with the highest count. If no element exists, return an empty string.<br>*getMinKey()* returns a *key* with the lowest count. If no element exists, return an empty string.<br><br>**Note**: each function must run in *O(1)* average time complexity.	O(1)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(1)**<br>Memory Complexity: **O(n)**	Doubly-Linked List + Hash Table	Single Hash Table	Single Doubly-Linked List	Two Hash Tables	A	**Correct!**<br><br>In this suggested solution, which is a little tricky to implement, you need to design a way to store key-value pairs and efficiently support the following operations in constant time: insert a new key-value pair, remove an existing key-value pair, and get a key-value pair with the maximum or minimum key.<br><br>To do so, we use a doubly linked list of buckets with a hash table that maps each key to its corresponding bucket. Each bucket contains a set of keys that share the same value. To support the three operations, the implementation updates the linked list and hash table accordingly, moving keys between buckets as necessary.	**Incorrect!**<br><br>One possible solution is to use a single hash table to store both the key-value pairs and the frequency count of each key. When a key is accessed, the frequency count is incremented and the hash table is scanned to find the key with the highest/lowest frequency count. <br><br>However, this approach would require scanning the entire hash table each time a key is accessed, making it inefficient for large datasets.	**Not quite!**<br><br>It's true that one could use a linked list to store the key-value pairs and the frequency count of each key. Each node in the linked list would contain a key, a value, and a frequency count. When a key is accessed, its frequency count is incremented and the linked list is scanned to find the key with the highest/lowest frequency count.<br><br>However, this approach would require scanning the entire linked list each time a key is accessed - this makes it inefficient for large datasets.	**Suboptimal!**<br><br>It is possible to use two separate hash tables to store the key-value pairs and the frequency count of each key. When a key is accessed, the frequency count is incremented and the hash table with the frequency counts is scanned to find the key with the highest/lowest frequency count.<br><br>However, in the worst case, all keys could have the same hash code, and the hash table could end up having all keys collide in the same bucket, resulting in O(n) time complexity for accessing an element in the hash table - this is a rare case, and the hash table data structure has been designed to minimize collisions, but it can happen.	1) Initialize two hash tables (one to store string counts, the other to store string sets for each count).<br>2) *inc*: Add the key with count 1 if not already present; otherwise, increment its count. Move the key from the old count set to the new count set.<br>3) *dec*: Decrement the key's count. If count becomes 0, remove from both count map and old count set. If positive, move key to new count set.<br> 4) *getMaxKey*: Return key from set of maximum count (tracked).<br> 5) *getMinKey*: Return key from set of minimum count (tracked).<br><br>This method has O(1) average time complexity for all operations, while worst case requires O(n) space (n = distinct strings inserted).  We want O(1) space!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/All%20O%60one%20Data%20Structure.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/All%20O%60one%20Data%20Structure.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/All%20O%60one%20Data%20Structure.java	https://youtu.be/qeL8baEmpfM
Coding Interviews	Hash Tables	LRU Cache	https://leetcode.com/problems/lru-cache/	Design a data structure that follows the constraints of a **Least Recently Used (LRU) cache**.<br><br>Implement the LRUCache class:<br>*LRUCache(int capacity)* initializes the LRU cache with **positive** size *capacity*.<br>*int get(int key)* returnn the value of the *key* if the key exists, otherwise return *-1*.<br>*void put(int key, int value)* updates the value of the *key* if the *key* exists. Otherwise, add the *key-value* pair to the cache. If the number of keys exceeds the *capacity* from this operation, evict the least recently used key.<br><br>The functions *get* and *put* must each run in *O(1)* average time complexity.	O(1)	O(n)	For the get and put functions, we're expecting an optimized solution of:<br>Time Complexity: **O(1)**<br>Memory Complexity: **O(n)**<br><br>N.B. there are alternative 'better' approaches to investigate for this famous interview problem!	Linear Search	Doubly-Linked List + Hash Table	Single Hash Table	Two Arrays	B	**Hmmâ€¦not really!**<br><br>The idea is to store the timestamp of each key-value pair in a separate hash table, and then perform a linear search over it to find the least recently used element when the cache is full.<br><br>However, this approach would also have a time complexity of O(n) for both get and put operations, where n is the number of elements in the cache, making it unsuitable for high-performance systems.	**Correct!**<br><br>One implementation can maintain a doubly linked list to keep track of the order in which the elements were accessed, with the most recently accessed element at the front and the least recently accessed element at the back.<br><br>It also could use an hash table to store key-value pairs - and keep the corresponding iterators in the doubly linked list.	**Incorrect!**<br><br>Using a hash table will store the key-value pairs, but lacks a mechanism to track the order in which the elements were accessed. This would make it impossible to determine the least recently used element when the cache is full, and the implementation would require a linear scan of the hash table to evict an element.<br><br>As a result, this approach would also have a time complexity of O(n) for both get and put operations, where n is the size of the hash table.	**Incorrect!**<br><br>It's true that one approach could be to use an array to store the key-value pairs, with a separate array to store the timestamps of each key-value pair.<br><br>However, this approach would require a linear search over the timestamp array to find the least recently used element when the cache is full, resulting in a time complexity of O(n) for the eviction operation. There's no way to do an O(1) 'lazy deletion' for this!	Here, my own suggested implementation is almost identical to the Brute Force approachâ€¦my apologies!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/LRU%20Cache.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/LRU%20Cache.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/LRU%20Cache.java	https://youtu.be/c3P9Iihe8ts
Coding Interviews	Hash Tables	LFU Cache	https://leetcode.com/problems/lfu-cache/	Design and implement a data structure for a **Least Frequently Used (LFU)** cache.<br>*LFUCache(int capacity)* initializes the cache with a given *capacity*.<br>*int get(int key)* retrieves the value of the *key* from the cache if it exists, otherwise returns *-1*.<br>*void put(int key, int value)* updates the *key* value if present, or inserts the *key* if not already present. When the cache is full, it **removes the least frequently used key** before inserting a new item. If there is a tie in frequency, the **least recently used key** is invalidated.<br><br>The cache maintains a **use counter** for each *key* to determine the **least frequently used key**. When a *key* is initially inserted, its **use counter** is set to *1* (due to the *put* operation). The **use counter** for a *key* is incremented upon calling *get* or *put* on that *key*.<br><br>The *get* and *put* functions must each run in *O(1)* average time complexity.	O(1)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(1)**<br>Memory Complexity: **O(n)**	Sorted List	Frequency Count	Hash Table + Min-Heap	Hash Table + Doubly Linked List	D	Not the best answer from the selection.<br><br>This **can** be a correct implementation of the LFU cache, but a sorted list results in **O(n)** time complexity for both *get* and *put* operations, violating the **O(1)** time complexity requirement.	**Poor** space complexity.<br><br>The method here would incorporate separate counters that tell us the frequency of use AND time of last access for each key in the cache.<br><br>This requires additional space complexity, and can result in incorrect behavior when there is a tie between keys with the same frequency.	**Not quite!**<br><br>The approach involves using a hash table to store the key-value pairs, and a min-heap to keep track of the least frequently used entries. Each entry in the min-heap is a key-value pair, maintained along with its frequency of use.<br><br>This approach would have **O(log(n))** complexity for accessing and updating the min-heap. When a key is accessed or updated, we update its frequency of use in the hash table and update its position in the min-heap. When a new key is inserted, add it to the hash table with a frequency of 1 and insert it into the min-heap. When the cache reaches its capacity, evict the least frequently used key by removing it from the min-heap and hash table.	**Correct!**<br><br>1) Each node in the linked list can stores a frequency, and a LIST of keys with that frequency.<br>2) When a key is accessed (via get or put), its frequency is incremented, and it is moved to the correct position in the linked list.<br>3) When the cache reaches its capacity, the least frequently used key is removed from the linked list and the hash table.<br><br>This yields an O(1) approach for both the *get* and *put* operations.	Achieving O(1) complexity is highly fanciful!	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/LFU%20Cache.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/LFU%20Cache.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/LFU%20Cache.java	https://youtu.be/2m4mdnocGFM
Coding Interviews	Hash Tables	Insert Delete GetRandom O(1)	https://leetcode.com/problems/insert-delete-getrandom-o1/	Implement the *RandomizedSet* class:<br>*RandomizedSet()* initializes the *RandomizedSet* object.<br>*bool insert(int val)* inserts an item *val* into the set if not present. Returns *true* if the item was not present, *false* otherwise.<br>*bool remove(int val)* removes an item *val* from the set if present. Returns *true* if the item was present, *false* otherwise.<br>*int getRandom()* returns a random element from the current set of elements (it's guaranteed that at least one element exists when this method is called). Each element must have the **same probability** of being returned.<br><br>You must implement the functions of the class such that each function works in **average O(1) time complexity**.	O(1)	O(n)	We're expecting an optimized solution of:<br>Time Complexity: **O(1)**<br>Memory Complexity: **O(n)**	Vector + Hash Table	Doubly Linked List + Hash Table	Two Arrays	Binary Search Tree + Vector	A	**Correct!**<br><br>The vector stores the actual elements in the set, while the map simply maps a value to its corresponding index in the values vector. *insert* will add a new element to the values vector, but only if it doesn't already exist in the set.<br><br>*remove* will first check if the element exists in the set, and will then remove it from the values vector by swapping it with the last element in a **lazy deletion**.<br><br>It's important that the swapped element's entry is updated in the map at the same time. Finally, in the C++/Java implementations of the solution, the *getRandom* operation returns a random element from the values vector using the *rand()* function. Python can use random/choice for the same purpose.	**Not the best** from the options available due to the additional space.<br><br>This linked list would be used to store the elements, with the hash table recording the index of each element. The *insertion* and *removal* operations would take O(n) time complexity in the worst case due to the need to traverse the linked list to find the element.<br><br>This solution would also have O(n) space complexity...	**Incorrect**, due to the additional space complexity!<br><br>Presumably, we use one to store the elements, while the other flags if an element is present in the set.<br><br>The insertion and removal operations would take O(n) time complexity in the worst case due to the need to shift elements in the array. However, this solution would have O(n) space complexity.	**Incorrect!**<br><br>This idea uses a binary search tree to store the elements and a vector to store the elements in the order they were inserted.<br><br>Insertion and removal operations would take O(log(n)) time complexity in the worst case due to the binary search tree's lookup time complexity.	A brute-force approach to achieve O(1) complexity is probably not possible.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/Insert%20Delete%20GetRandom%20O(1).cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/Insert%20Delete%20GetRandom%20O(1).py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/Insert%20Delete%20GetRandom%20O(1).java	https://youtu.be/4b3PwI5iVhU
Coding Interviews	Hash Tables	First Unique Number	https://leetcode.com/problems/first-unique-number/	You have a queue of integers, you need to retrieve the first unique integer in the queue.<br><br>Implement the *FirstUnique* class:<br>*FirstUnique(int[] nums)* initializes the object with the numbers in the queue.<br>*int showFirstUnique()* returns the value of the **first unique integer** of the queue, and returns **-1** if there is no such integer.<br>*void add(int value)* inserts a value to the queue.	O(1)	O(n)	For the **add()** and **get()** functions, we're expecting an optimized solution of:<br>Time Complexity: **O(1)**<br>Memory Complexity: **O(n)**	Single Hash Table	Queue + Set	Doubly-Linked List + Hash Table	Sorted List	C	**Not quite!**<br><br>This idea uses a single hash table to keep track of the frequency of each number in the input array, and returns the first number with a frequency of 1.<br><br>The time complexity is O(n) for preprocessing the input array, although O(1) for all subsequent queries.	**Not quite!**  Combining a queue and set would result in O(n) time complexity!<br><br>We can use a queue to maintain the order of the unique numbers, while the set to keeps track of the numbers that have been added to the data structure. For the add operation, we simply add the number to the queue - and to the set if it is not already there. If it's already in the set, we can remove it from the queue! For the showFirstUnique operation, we iterate through the queue until we find the first number that is NOT in the set.<br><br>However, this approach has a time complexity of O(n) for both add and showFirstUnique operations.	**Correct!**<br><br>This approach is very efficient compared to the others for the following reasons. The doubly linked list maintains the order of the unique numbers that have been added to the data structure, while the hash table maps the value of a number to its corresponding node in the uniqueNumbers list.<br><br>Essentially, the list maintains the order of the unique numbers, while the map helps with efficient lookup of nodes in the list.	**Sorting ruins the complexity!**<br><br>This approach involves using a sorted list to maintain the order of the unique numbers. We can insert a number in the sorted list if it is not already in the list, and remove it from the list if it is already present.<br><br>For the showFirstUnique operation, we can simply return the first number in the sorted list. This approach has a time complexity of O(n log(n)) for the add operation and O(1) for the showFirstUnique operation.	Our method would involve the following:<br>1) Initialize an empty list to keep track of unique integers.<br>2) For each integer in the queue, check if it exists in both the queue and the unique list.<br>3) If the integer is not in the unique list, check if it is unique in the queue by checking the remaining integers after it.<br>4) If the integer is unique, add it to the unique list.<br>5) If the integer is not unique, ignore it.<br>6) After iterating through the queue, return the first element in the unique list as the first unique integer. If the unique list is empty, return -1.<br><br>This approach has a time complexity of O(n^2) since it requires nested iterations through the queue to check for uniqueness.	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPackSolutionsCPP/First%20Unique%20Number.cpp	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsPythonSolutions/First%20Unique%20Number.py	https://raw.githubusercontent.com/rabogan/tentativeSolutions/main/CodingInterviewsJavaSolutions/First%20Unique%20Number.java	https://youtu.be/fqSJjoY4d9M